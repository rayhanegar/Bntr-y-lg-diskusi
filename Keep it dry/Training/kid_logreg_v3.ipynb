{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep-it-dry! LogisticRegression\n",
    "Dataset: ki_ro_ros.csv with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./../Preprocessing/kid_train_ki_ro_ros.csv', index_col=0)\n",
    "df_test = pd.read_csv('./../Preprocessing/kid_test_ki_ro.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>measurement_4</th>\n",
       "      <th>...</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.866789</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.191386</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.582308</td>\n",
       "      <td>-0.155224</td>\n",
       "      <td>-0.823018</td>\n",
       "      <td>1.817328</td>\n",
       "      <td>-0.416608</td>\n",
       "      <td>-0.826421</td>\n",
       "      <td>-0.996926</td>\n",
       "      <td>-0.798281</td>\n",
       "      <td>0.405153</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.768774</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.320974</td>\n",
       "      <td>-0.146396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783846</td>\n",
       "      <td>1.031983</td>\n",
       "      <td>-0.658824</td>\n",
       "      <td>0.022965</td>\n",
       "      <td>-0.627395</td>\n",
       "      <td>-0.310259</td>\n",
       "      <td>-0.299693</td>\n",
       "      <td>-0.369968</td>\n",
       "      <td>-0.127292</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.819112</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.204120</td>\n",
       "      <td>-0.062312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989231</td>\n",
       "      <td>-0.298507</td>\n",
       "      <td>-0.298414</td>\n",
       "      <td>1.089248</td>\n",
       "      <td>0.777147</td>\n",
       "      <td>1.355888</td>\n",
       "      <td>-0.453893</td>\n",
       "      <td>0.677069</td>\n",
       "      <td>-0.248529</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.437692</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-0.410661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801538</td>\n",
       "      <td>0.121677</td>\n",
       "      <td>-0.422506</td>\n",
       "      <td>-0.882568</td>\n",
       "      <td>-0.259759</td>\n",
       "      <td>-0.239060</td>\n",
       "      <td>0.601434</td>\n",
       "      <td>0.327001</td>\n",
       "      <td>0.808704</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.342337</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.169663</td>\n",
       "      <td>0.912162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.840000</td>\n",
       "      <td>0.540156</td>\n",
       "      <td>0.372890</td>\n",
       "      <td>0.374217</td>\n",
       "      <td>0.401703</td>\n",
       "      <td>-1.695250</td>\n",
       "      <td>-0.935963</td>\n",
       "      <td>-0.016735</td>\n",
       "      <td>-0.790371</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loading  attribute_0  attribute_1  attribute_2  attribute_3  \\\n",
       "0 -0.866789          7.0          8.0            9            5   \n",
       "1 -0.768774          7.0          8.0            9            5   \n",
       "2 -0.819112          7.0          8.0            9            5   \n",
       "3 -0.437692          7.0          8.0            9            5   \n",
       "4  1.342337          7.0          8.0            9            5   \n",
       "\n",
       "   measurement_0  measurement_1  measurement_2  measurement_3  measurement_4  \\\n",
       "0       0.000000       0.000000          -0.50       0.191386       0.587838   \n",
       "1       1.166667      -0.833333          -0.75       0.320974      -0.146396   \n",
       "2       0.833333      -1.166667          -0.25       0.204120      -0.062312   \n",
       "3       1.000000      -1.000000           0.00      -0.366667      -0.410661   \n",
       "4       0.333333      -1.000000           0.50       1.169663       0.912162   \n",
       "\n",
       "   ...  measurement_9  measurement_10  measurement_11  measurement_12  \\\n",
       "0  ...      -0.582308       -0.155224       -0.823018        1.817328   \n",
       "1  ...       0.783846        1.031983       -0.658824        0.022965   \n",
       "2  ...       0.989231       -0.298507       -0.298414        1.089248   \n",
       "3  ...       0.801538        0.121677       -0.422506       -0.882568   \n",
       "4  ...      -0.840000        0.540156        0.372890        0.374217   \n",
       "\n",
       "   measurement_13  measurement_14  measurement_15  measurement_16  \\\n",
       "0       -0.416608       -0.826421       -0.996926       -0.798281   \n",
       "1       -0.627395       -0.310259       -0.299693       -0.369968   \n",
       "2        0.777147        1.355888       -0.453893        0.677069   \n",
       "3       -0.259759       -0.239060        0.601434        0.327001   \n",
       "4        0.401703       -1.695250       -0.935963       -0.016735   \n",
       "\n",
       "   measurement_17  failure  \n",
       "0        0.405153      0.0  \n",
       "1       -0.127292      0.0  \n",
       "2       -0.248529      0.0  \n",
       "3        0.808704      0.0  \n",
       "4       -0.790371      0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>measurement_4</th>\n",
       "      <th>...</th>\n",
       "      <th>measurement_8</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.059136</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.138951</td>\n",
       "      <td>-1.168919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274792</td>\n",
       "      <td>-0.482308</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.579540</td>\n",
       "      <td>1.075678</td>\n",
       "      <td>-1.388928</td>\n",
       "      <td>0.417316</td>\n",
       "      <td>-0.634221</td>\n",
       "      <td>0.570330</td>\n",
       "      <td>-0.435202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.183139</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.073783</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265708</td>\n",
       "      <td>0.463846</td>\n",
       "      <td>-1.213362</td>\n",
       "      <td>-0.441432</td>\n",
       "      <td>0.397704</td>\n",
       "      <td>1.314407</td>\n",
       "      <td>0.356512</td>\n",
       "      <td>-0.104508</td>\n",
       "      <td>-1.061511</td>\n",
       "      <td>-1.068447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.210763</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.517228</td>\n",
       "      <td>-0.941441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.940954</td>\n",
       "      <td>0.241538</td>\n",
       "      <td>0.519687</td>\n",
       "      <td>-0.571355</td>\n",
       "      <td>-0.419624</td>\n",
       "      <td>-1.599006</td>\n",
       "      <td>-0.148114</td>\n",
       "      <td>1.068135</td>\n",
       "      <td>-0.193578</td>\n",
       "      <td>-0.276961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.199304</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.948689</td>\n",
       "      <td>-0.635886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052233</td>\n",
       "      <td>0.277692</td>\n",
       "      <td>1.155935</td>\n",
       "      <td>-1.554987</td>\n",
       "      <td>-0.406054</td>\n",
       "      <td>-0.081618</td>\n",
       "      <td>-0.184492</td>\n",
       "      <td>-1.209016</td>\n",
       "      <td>-0.152872</td>\n",
       "      <td>-0.696814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750358</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.017603</td>\n",
       "      <td>0.719219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093868</td>\n",
       "      <td>0.723846</td>\n",
       "      <td>-0.883582</td>\n",
       "      <td>-0.692583</td>\n",
       "      <td>0.120042</td>\n",
       "      <td>0.322214</td>\n",
       "      <td>0.083671</td>\n",
       "      <td>-0.848361</td>\n",
       "      <td>0.317051</td>\n",
       "      <td>0.644913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loading  attribute_0  attribute_1  attribute_2  attribute_3  \\\n",
       "0 -0.059136          5.0          6.0            6            4   \n",
       "1 -0.183139          5.0          6.0            6            4   \n",
       "2 -0.210763          5.0          6.0            6            4   \n",
       "3 -0.199304          5.0          6.0            6            4   \n",
       "4  1.750358          5.0          6.0            6            4   \n",
       "\n",
       "   measurement_0  measurement_1  measurement_2  measurement_3  measurement_4  \\\n",
       "0      -0.166667       0.166667            0.0       1.138951      -1.168919   \n",
       "1       0.666667       0.000000           -1.5       0.073783       0.144144   \n",
       "2       0.166667       0.666667           -0.5       0.517228      -0.941441   \n",
       "3       0.166667       0.500000            1.0      -0.948689      -0.635886   \n",
       "4       1.166667       1.333333            0.5       0.017603       0.719219   \n",
       "\n",
       "   ...  measurement_8  measurement_9  measurement_10  measurement_11  \\\n",
       "0  ...      -0.274792      -0.482308       -0.126795       -0.579540   \n",
       "1  ...       0.265708       0.463846       -1.213362       -0.441432   \n",
       "2  ...      -0.940954       0.241538        0.519687       -0.571355   \n",
       "3  ...      -0.052233       0.277692        1.155935       -1.554987   \n",
       "4  ...       0.093868       0.723846       -0.883582       -0.692583   \n",
       "\n",
       "   measurement_12  measurement_13  measurement_14  measurement_15  \\\n",
       "0        1.075678       -1.388928        0.417316       -0.634221   \n",
       "1        0.397704        1.314407        0.356512       -0.104508   \n",
       "2       -0.419624       -1.599006       -0.148114        1.068135   \n",
       "3       -0.406054       -0.081618       -0.184492       -1.209016   \n",
       "4        0.120042        0.322214        0.083671       -0.848361   \n",
       "\n",
       "   measurement_16  measurement_17  \n",
       "0        0.570330       -0.435202  \n",
       "1       -1.061511       -1.068447  \n",
       "2       -0.193578       -0.276961  \n",
       "3       -0.152872       -0.696814  \n",
       "4        0.317051        0.644913  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_id = df_test[['id']]\n",
    "df_test.drop(columns=['id', 'product_code', 'product_code_F', 'product_code_G', 'product_code_H', 'product_code_I'], inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df_train[df_train.columns[:-1]]\n",
    "y_df = df_train[df_train.columns[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 components score: 0.5630705989197458\n",
      "11 components score: 0.5646001625161321\n",
      "12 components score: 0.5645523636537451\n",
      "13 components score: 0.563620285837197\n",
      "14 components score: 0.5632378949381005\n",
      "15 components score: 0.5640743750298743\n",
      "16 components score: 0.5672290999474212\n",
      "17 components score: 0.567037904497873\n",
      "18 components score: 0.567037904497873\n",
      "19 components score: 0.5656039386262607\n",
      "20 components score: 0.5663687204244539\n",
      "21 components score: 0.5667033124611635\n",
      "22 components score: 0.565795134075809\n",
      "Best number of components based on LogisticRegression performance: 16\n"
     ]
    }
   ],
   "source": [
    "n_components_range = range(10, 23)  # Explore components from 10 to 22\n",
    "\n",
    "best_n_components = None\n",
    "best_score = -np.inf  # Initialize with a negative infinity\n",
    "\n",
    "for n_components in n_components_range:\n",
    "  # Apply PCA with current n_components\n",
    "  pca = PCA(n_components=n_components)\n",
    "  pca_data = pca.fit_transform(X_df)\n",
    "\n",
    "  # Train LogisticRegression on transformed data\n",
    "  model = LogisticRegression()\n",
    "  model.fit(pca_data, y_df)\n",
    "\n",
    "  # Evaluate performance on testing set (e.g., using F1 score)\n",
    "  score = model.score(pca.transform(X_df), y_df)\n",
    "  print(f\"{n_components} components score: {score}\")\n",
    "\n",
    "  # Update best component and score if performance improves\n",
    "  if score > best_score:\n",
    "    best_n_components = n_components\n",
    "    best_score = score\n",
    "\n",
    "print(\"Best number of components based on LogisticRegression performance:\", best_n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=16)\n",
    "X_df_pca = pca.fit_transform(X_df)\n",
    "df_test_pca = pca.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_df_pca, y_df, test_size=.75, random_state=42, stratify=y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'solver': ['liblinear', 'lbfgs', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    'penalty': ['l2', 'elasticnet'],\n",
    "    'C': np.logspace(-4, 4, 5)  # Search across different C values in log space\n",
    "}\n",
    "\n",
    "# Define GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='f1')  # Use F1 score for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "                         ~~^~~~~~~~~~\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\RAYHAN EGAR\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.53792449 0.53786123 0.53724097 0.53724097 0.53779353 0.53724097\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.54014595 0.54014595 0.54014595 0.54014595 0.54014595 0.54009275\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.54090155 0.54090155 0.54090155 0.54090155 0.54090155 0.54090155\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.54090155 0.54090155 0.54090155 0.54090155 0.54084732 0.54090155\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.54090155 0.54090155 0.54090155 0.54090155 0.54084732 0.54090155\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-04, 1.e-02, 1.e+00, 1.e+02, 1.e+04]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                    &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-04, 1.e-02, 1.e+00, 1.e+02, 1.e+04]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                    &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={'C': array([1.e-04, 1.e-02, 1.e+00, 1.e+02, 1.e+04]),\n",
       "                         'penalty': ['l2', 'elasticnet'],\n",
       "                         'solver': ['liblinear', 'lbfgs', 'newton-cg',\n",
       "                                    'newton-cholesky', 'sag', 'saga']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV fitting\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best f1-score: 0.5409015493720147\n"
     ]
    }
   ],
   "source": [
    "logreg_best = grid_search.best_estimator_\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best f1-score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg_best.predict(df_test_pca)\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=['failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission = pd.concat([df_test_id, y_pred_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26570</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26572</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26573</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26574</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  failure\n",
       "0  26570      0.0\n",
       "1  26571      0.0\n",
       "2  26572      0.0\n",
       "3  26573      0.0\n",
       "4  26574      1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission.to_csv('./../Submission/kid_submission_logreg_pca.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

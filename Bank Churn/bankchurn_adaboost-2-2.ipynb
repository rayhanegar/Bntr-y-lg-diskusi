{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0a4b3ab8aa3e490fa77749281397f11e","deepnote_cell_type":"text-cell-h1"},"source":"# Spaceship Titanic ensembe Submission","block_group":"082f42d739ae4c33b25722d4d688de17"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1716146783748,"execution_millis":24733,"deepnote_to_be_reexecuted":false,"cell_id":"19051feb4e6147099007e219965d66f1","deepnote_cell_type":"code"},"source":"!pip install xgboost==2.0.3","block_group":"d312077bc5c24672a6ec875447391fed","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting xgboost==2.0.3\n  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from xgboost==2.0.3) (1.9.3)\nRequirement already satisfied: numpy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from xgboost==2.0.3) (1.23.4)\nInstalling collected packages: xgboost\nSuccessfully installed xgboost-2.0.3\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/e667dcb0-8319-4adb-b22b-ccee9da62587","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1716146808490,"execution_millis":3730,"deepnote_to_be_reexecuted":false,"cell_id":"dd9832dbe33b461cbf43848c75c64ca2","deepnote_cell_type":"code"},"source":"!pip install lightgbm==4.3.0","block_group":"34f2a61ca65e488184ff3961c71caf10","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting lightgbm==4.3.0\n  Downloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl (3.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from lightgbm==4.3.0) (1.9.3)\nRequirement already satisfied: numpy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from lightgbm==4.3.0) (1.23.4)\nInstalling collected packages: lightgbm\nSuccessfully installed lightgbm-4.3.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/efd11442-1e54-4f09-a060-153f1d6e457f","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1716146812224,"execution_millis":4638,"deepnote_to_be_reexecuted":false,"cell_id":"28981dff5fd748f3aeeec494a743e7b3","deepnote_cell_type":"code"},"source":"!pip install lightgbm==4.3.0","block_group":"e4967277cb7b4dcc913d5d7e266f7df1","execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: lightgbm==4.3.0 in /root/venv/lib/python3.9/site-packages (4.3.0)\nRequirement already satisfied: numpy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from lightgbm==4.3.0) (1.23.4)\nRequirement already satisfied: scipy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from lightgbm==4.3.0) (1.9.3)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/46a82454-5cd2-4092-8aa7-ae279acc6b60","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1716146816865,"execution_millis":8355,"deepnote_to_be_reexecuted":false,"cell_id":"bb32d8f76e37441095e00da61b116b98","deepnote_cell_type":"code"},"source":"!pip install catboost==1.2.5","block_group":"b9a664b420444b7fbf25a0becde68b5e","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting catboost==1.2.5\n  Downloading catboost-1.2.5-cp39-cp39-manylinux2014_x86_64.whl (98.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from catboost==1.2.5) (1.23.4)\nRequirement already satisfied: plotly in /shared-libs/python3.9/py/lib/python3.9/site-packages (from catboost==1.2.5) (5.10.0)\nRequirement already satisfied: scipy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from catboost==1.2.5) (1.9.3)\nRequirement already satisfied: six in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from catboost==1.2.5) (1.16.0)\nCollecting graphviz\n  Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib in /shared-libs/python3.9/py/lib/python3.9/site-packages (from catboost==1.2.5) (3.6.0)\nRequirement already satisfied: pandas>=0.24 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from catboost==1.2.5) (2.1.4)\nRequirement already satisfied: pytz>=2020.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pandas>=0.24->catboost==1.2.5) (2022.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from pandas>=0.24->catboost==1.2.5) (2.8.2)\nRequirement already satisfied: tzdata>=2022.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pandas>=0.24->catboost==1.2.5) (2022.5)\nRequirement already satisfied: pyparsing>=2.2.1 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (3.0.9)\nRequirement already satisfied: fonttools>=4.22.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (4.37.4)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (21.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (1.4.4)\nRequirement already satisfied: contourpy>=1.0.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (1.0.5)\nRequirement already satisfied: pillow>=6.2.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (9.2.0)\nRequirement already satisfied: cycler>=0.10 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (0.11.0)\nRequirement already satisfied: tenacity>=6.2.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from plotly->catboost==1.2.5) (8.1.0)\nInstalling collected packages: graphviz, catboost\nSuccessfully installed catboost-1.2.5 graphviz-0.20.3\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/25add7bc-a7ed-48e1-8d8e-365b083f5d32","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1716146825228,"execution_millis":964,"deepnote_to_be_reexecuted":false,"cell_id":"44c1ee706bff4746a3efec8a784dbbb1","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import StackingClassifier","block_group":"6d67ae98cbb84c27b03fe6f9075b0099","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"8753058da5a8476f932fe1ff444248f5","deepnote_cell_type":"text-cell-h1"},"source":"# Bring the Data In","block_group":"0c79d79c638f4ac7a0e36c426c763934"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1716146826202,"execution_millis":144142,"deepnote_to_be_reexecuted":false,"cell_id":"802343574e4a46f5a2dff7c815885a2d","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nfrom sklearn.metrics import make_scorer, accuracy_score\n\n# Load data\nX_df = pd.read_csv('preprocessedbankchurn_train.csv')\nX_df.drop(\"Exited\", axis=1, inplace=True)\ny_df = pd.read_csv('preprocessedbankchurn_train.csv')['Exited']\nX_submission = pd.read_csv('preprocessedbankchurn_test.csv')\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=42)\n\n# Base estimator\nbase_estimator = DecisionTreeClassifier(max_depth=1)\n\n# Create pipeline\npipeline = Pipeline([\n    ('scaler', StandardScaler()),  # Normalize data\n    ('classifier', AdaBoostClassifier(base_estimator=base_estimator))\n])\n\n\n# Define GridSearch parameters\nparameters = {\n    'classifier__n_estimators': [200],\n    'classifier__learning_rate': [1]\n}\n\n\n\ndef custom_accuracy(y_true, y_prob, threshold=0.5):\n    y_pred = (y_prob[:, 1] >= threshold).astype(int)\n    return accuracy_score(y_true, y_pred)\n\n# Membuat scorer kustom\naccuracy_scorer = make_scorer(custom_accuracy, needs_proba=True)\n\n# Menggunakan dalam GridSearchCV\ngrid_search = GridSearchCV(pipeline, parameters, scoring=accuracy_scorer, cv=5)\ngrid_search.fit(X_train, y_train)\n\n\n# Evaluate the model\nbest_model = grid_search.best_estimator_\ny_pred_proba = best_model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Accuracy on test set:\", accuracy_score(y_test, y_pred_proba))\n\n# Evaluation on the test set\ny_pred = best_model.predict(X_test)\nprint(classification_report(y_test, y_pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))\n\n# Fit the model on all training data\ngrid_search.fit(X_df, y_df)\n\n\n","block_group":"1ef835adfdc04c2c8f92f4e62c1cbe16","execution_count":null,"outputs":[{"name":"stderr","text":"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 312, in _score\n    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n  File \"/tmp/ipykernel_109/1524278816.py\", line 38, in custom_accuracy\n    y_pred = (y_prob[:, 1] >= threshold).astype(int)\nIndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n\n  warnings.warn(\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 312, in _score\n    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n  File \"/tmp/ipykernel_109/1524278816.py\", line 38, in custom_accuracy\n    y_pred = (y_prob[:, 1] >= threshold).astype(int)\nIndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n\n  warnings.warn(\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 312, in _score\n    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n  File \"/tmp/ipykernel_109/1524278816.py\", line 38, in custom_accuracy\n    y_pred = (y_prob[:, 1] >= threshold).astype(int)\nIndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n\n  warnings.warn(\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 312, in _score\n    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n  File \"/tmp/ipykernel_109/1524278816.py\", line 38, in custom_accuracy\n    y_pred = (y_prob[:, 1] >= threshold).astype(int)\nIndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n\n  warnings.warn(\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 312, in _score\n    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n  File \"/tmp/ipykernel_109/1524278816.py\", line 38, in custom_accuracy\n    y_pred = (y_prob[:, 1] >= threshold).astype(int)\nIndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n\n  warnings.warn(\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan]\n  warnings.warn(\nBest parameters: {'classifier__learning_rate': 1, 'classifier__n_estimators': 200}\n","output_type":"stream"},{"output_type":"error","ename":"ValueError","evalue":"Classification metrics can't handle a mix of binary and continuous targets","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn [6], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Get probabilities for the positive class\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy on test set:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_proba\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Evaluation on the test set\u001b[39;00m\n\u001b[1;32m     56\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/1a8367f8-2412-4c33-b266-86bc3f6e337e","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715877080195,"execution_millis":395,"deepnote_to_be_reexecuted":true,"cell_id":"54e00dd181df41d3a2d57b0f09c383dd","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import StackingClassifier\n\n# Load data\nX_df = pd.read_csv('spaceship_train_X_v2.csv')\ny_df = pd.read_csv('spaceship_train_y.csv')\nX_submission = pd.read_csv('spaceship_test_X_v2.csv')\n\ny_df.drop('Unnamed: 0', axis=1, inplace=True)\n\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=42)\n","block_group":"743f0a09a56b4139a32a21d44c6acf21","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715878151736,"execution_millis":108432,"deepnote_to_be_reexecuted":true,"cell_id":"6afc0c5268aa45e5b80f7aa0e07a01a4","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import StackingClassifier\n\n# Load data\nX_df = pd.read_csv('spaceship_train_X_v2.csv')\ny_df = pd.read_csv('spaceship_train_y.csv')\nX_submission = pd.read_csv('spaceship_test_X_v2.csv')\n\n# Drop unnecessary columns\nX_df.drop('PassengerId', axis=1, inplace=True)\ny_df.drop('Unnamed: 0', axis=1, inplace=True)\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=42)\n\n# Define base models\nbase_models = [\n    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, enable_categorical=True)),\n    ('lgbm', LGBMClassifier(random_state=42)),\n    ('catboost', CatBoostClassifier(verbose=0, random_state=42))\n]\n\n# Define the meta-model\nmeta_model = CatBoostClassifier(verbose=0, random_state=42)\n\n# Create the stacking ensemble\nstacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n\n# Hyperparameter tuning for the stacking ensemble\nparam_grid = {\n    'rf__n_estimators': [100],\n    'rf__max_depth': [10],\n    'gb__n_estimators': [100],\n    'gb__learning_rate': [0.1],\n    'xgb__n_estimators': [100],\n    'xgb__learning_rate': [0.1],\n    'lgbm__n_estimators': [100],\n    'lgbm__learning_rate': [0.1],\n    'catboost__iterations': [100],\n    'catboost__learning_rate': [0.1],\n    'final_estimator__iterations': [100],\n    'final_estimator__learning_rate': [0.1]\n}\n\n# Perform hyperparameter tuning with GridSearchCV\ngrid_search = GridSearchCV(estimator=stacking_clf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy', error_score='raise')\ngrid_search.fit(X_train, y_train.values.ravel())\n\n# Predict and evaluate\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Best model parameters: {grid_search.best_params_}')\nprint(f'Accuracy of stacking ensemble: {accuracy:.4f}')\n","block_group":"688e4cc851a645e3bcc6695207ae6f2f","execution_count":null,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2334, number of negative: 2302\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503451 -> initscore=0.013805\n[LightGBM] [Info] Start training from score 0.013805\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1841\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000257 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 3708, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503506 -> initscore=0.014024\n[LightGBM] [Info] Start training from score 0.014024\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000462 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000452 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1868, number of negative: 1841\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000258 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503640 -> initscore=0.014559\n[LightGBM] [Info] Start training from score 0.014559\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2333, number of negative: 2303\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000561 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503236 -> initscore=0.012942\n[LightGBM] [Info] Start training from score 0.012942\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1866, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 3708, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503236 -> initscore=0.012945\n[LightGBM] [Info] Start training from score 0.012945\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000606 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1866, number of negative: 1843\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503101 -> initscore=0.012402\n[LightGBM] [Info] Start training from score 0.012402\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1866, number of negative: 1843\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503101 -> initscore=0.012402\n[LightGBM] [Info] Start training from score 0.012402\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2333, number of negative: 2303\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000870 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503236 -> initscore=0.012942\n[LightGBM] [Info] Start training from score 0.012942\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1866, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3708, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503236 -> initscore=0.012945\n[LightGBM] [Info] Start training from score 0.012945\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000454 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000264 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1866, number of negative: 1843\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000476 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503101 -> initscore=0.012402\n[LightGBM] [Info] Start training from score 0.012402\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1866, number of negative: 1843\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000682 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503101 -> initscore=0.012402\n[LightGBM] [Info] Start training from score 0.012402\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002022 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n[LightGBM] [Info] Start training from score 0.013230\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2800, number of negative: 2763\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000654 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 5563, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503326 -> initscore=0.013302\n[LightGBM] [Info] Start training from score 0.013302\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2800, number of negative: 2763\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 5563, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503326 -> initscore=0.013302\n[LightGBM] [Info] Start training from score 0.013302\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2800, number of negative: 2763\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000656 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 5563, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503326 -> initscore=0.013302\n[LightGBM] [Info] Start training from score 0.013302\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2800, number of negative: 2763\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 5563, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503326 -> initscore=0.013302\n[LightGBM] [Info] Start training from score 0.013302\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2800, number of negative: 2764\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001301 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 5564, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503235 -> initscore=0.012941\n[LightGBM] [Info] Start training from score 0.012941\nBest model parameters: {'catboost__iterations': 100, 'catboost__learning_rate': 0.1, 'final_estimator__iterations': 100, 'final_estimator__learning_rate': 0.1, 'gb__learning_rate': 0.1, 'gb__n_estimators': 100, 'lgbm__learning_rate': 0.1, 'lgbm__n_estimators': 100, 'rf__max_depth': 10, 'rf__n_estimators': 100, 'xgb__learning_rate': 0.1, 'xgb__n_estimators': 100}\nAccuracy of stacking ensemble: 0.8010\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/f1e3ae9f-024a-444c-87d4-de3375a4f209","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715878937347,"execution_millis":165440,"deepnote_to_be_reexecuted":true,"cell_id":"516b88ede1174d12bdbaa622ca98eb3e","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import StackingClassifier\n\n# Load data\nX_df = pd.read_csv('spaceship_train_X_v2.csv')\ny_df = pd.read_csv('spaceship_train_y.csv')\nX_submission = pd.read_csv('spaceship_test_X_v2.csv')\n\n# Drop unnecessary column from y_df\ny_df.drop('Unnamed: 0', axis=1, inplace=True)\n\n# Define base models\nbase_models = [\n    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)),\n    ('lgbm', LGBMClassifier(random_state=42)),\n    ('catboost', CatBoostClassifier(verbose=0, random_state=42))\n]\n\n# Define the meta-model\nmeta_model = CatBoostClassifier(verbose=0, random_state=42)\n\n# Create the stacking ensemble\nstacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n\n# Hyperparameter tuning for the stacking ensemble\nparam_grid = {\n    'rf__n_estimators': [100],\n    'rf__max_depth': [10],\n    'gb__n_estimators': [100],\n    'gb__learning_rate': [0.1],\n    'xgb__n_estimators': [100],\n    'xgb__learning_rate': [0.1],\n    'lgbm__n_estimators': [100],\n    'lgbm__learning_rate': [0.1],\n    'catboost__iterations': [100],\n    'catboost__learning_rate': [0.1],\n    'final_estimator__iterations': [100],\n    'final_estimator__learning_rate': [0.1]\n}\n\n# Perform hyperparameter tuning with GridSearchCV\ngrid_search = GridSearchCV(estimator=stacking_clf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy', error_score='raise')\ngrid_search.fit(X_train,y_train)\n\n# Predict and evaluate\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Best model parameters: {grid_search.best_params_}')\nprint(f'Accuracy of stacking ensemble: {accuracy:.4f}')\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))","block_group":"5c076da9b4a943c6acf33da3d4d788f4","execution_count":null,"outputs":[{"name":"stderr","text":"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2334, number of negative: 2302\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503451 -> initscore=0.013805\n[LightGBM] [Info] Start training from score 0.013805\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1841\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 3708, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503506 -> initscore=0.014024\n[LightGBM] [Info] Start training from score 0.014024\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000454 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000452 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1868, number of negative: 1841\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000262 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503640 -> initscore=0.014559\n[LightGBM] [Info] Start training from score 0.014559\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2333, number of negative: 2303\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000658 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503236 -> initscore=0.012942\n[LightGBM] [Info] Start training from score 0.012942\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1866, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 3708, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503236 -> initscore=0.012945\n[LightGBM] [Info] Start training from score 0.012945\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1866, number of negative: 1843\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000454 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503101 -> initscore=0.012402\n[LightGBM] [Info] Start training from score 0.012402\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1866, number of negative: 1843\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503101 -> initscore=0.012402\n[LightGBM] [Info] Start training from score 0.012402\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2333, number of negative: 2303\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503236 -> initscore=0.012942\n[LightGBM] [Info] Start training from score 0.012942\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1866, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3708, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503236 -> initscore=0.012945\n[LightGBM] [Info] Start training from score 0.012945\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1867, number of negative: 1842\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503370 -> initscore=0.013481\n[LightGBM] [Info] Start training from score 0.013481\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1866, number of negative: 1843\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000672 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503101 -> initscore=0.012402\n[LightGBM] [Info] Start training from score 0.012402\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1866, number of negative: 1843\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 3709, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503101 -> initscore=0.012402\n[LightGBM] [Info] Start training from score 0.012402\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000808 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n[LightGBM] [Info] Start training from score 0.013230\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2800, number of negative: 2763\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000689 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 5563, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503326 -> initscore=0.013302\n[LightGBM] [Info] Start training from score 0.013302\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2800, number of negative: 2763\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 5563, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503326 -> initscore=0.013302\n[LightGBM] [Info] Start training from score 0.013302\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2800, number of negative: 2763\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000658 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 5563, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503326 -> initscore=0.013302\n[LightGBM] [Info] Start training from score 0.013302\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2800, number of negative: 2763\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000877 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 5563, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503326 -> initscore=0.013302\n[LightGBM] [Info] Start training from score 0.013302\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2800, number of negative: 2764\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 5564, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503235 -> initscore=0.012941\n[LightGBM] [Info] Start training from score 0.012941\nBest model parameters: {'catboost__iterations': 100, 'catboost__learning_rate': 0.1, 'final_estimator__iterations': 100, 'final_estimator__learning_rate': 0.1, 'gb__learning_rate': 0.1, 'gb__n_estimators': 100, 'lgbm__learning_rate': 0.1, 'lgbm__n_estimators': 100, 'rf__max_depth': 10, 'rf__n_estimators': 100, 'xgb__learning_rate': 0.1, 'xgb__n_estimators': 100}\nAccuracy of stacking ensemble: 0.8010\nConfusion Matrix:\n [[667 194]\n [152 726]]\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/2616a26d-af3a-423a-aa01-31100758d52f","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715881973044,"execution_millis":62,"deepnote_to_be_reexecuted":true,"cell_id":"dacd26a9f5ba48aeb79c558332413d3f","deepnote_cell_type":"code"},"source":"X_df.info()\nX_submission.info()","block_group":"79c9d5d114804447bbd2d7477e7ee86d","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'X_df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX_df\u001b[49m\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m      2\u001b[0m X_submission\u001b[38;5;241m.\u001b[39minfo()\n","\u001b[0;31mNameError\u001b[0m: name 'X_df' is not defined"]}],"outputs_reference":"dbtable:cell_outputs/1d1c10b6-edd2-45a8-a4a5-6fc2f32a2b7b","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715878308407,"execution_millis":113575,"deepnote_to_be_reexecuted":true,"cell_id":"2ef69b04b40c48f286f7b0ca477676fd","deepnote_cell_type":"code"},"source":"# For training, we use ALL data from spaceship_train_X_v2.csv and spaceship_train_y.csv\ngrid_search.fit(X_df, y_df['Transported'].values)\n# Prediksi data submission\ny_prediction = grid_search.predict(X_submission)\nprint(y_prediction)\n","block_group":"216fd01b42134a08b8d202e74ac610f5","execution_count":null,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2919, number of negative: 2876\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 5795, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503710 -> initscore=0.014841\n[LightGBM] [Info] Start training from score 0.014841\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2336, number of negative: 2300\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000571 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503883 -> initscore=0.015531\n[LightGBM] [Info] Start training from score 0.015531\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2335, number of negative: 2301\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503667 -> initscore=0.014668\n[LightGBM] [Info] Start training from score 0.014668\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2335, number of negative: 2301\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000806 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503667 -> initscore=0.014668\n[LightGBM] [Info] Start training from score 0.014668\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2335, number of negative: 2301\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503667 -> initscore=0.014668\n[LightGBM] [Info] Start training from score 0.014668\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2335, number of negative: 2301\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000748 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1869\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 35\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503667 -> initscore=0.014668\n[LightGBM] [Info] Start training from score 0.014668\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2918, number of negative: 2877\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 5795, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503538 -> initscore=0.014150\n[LightGBM] [Info] Start training from score 0.014150\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2335, number of negative: 2301\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503667 -> initscore=0.014668\n[LightGBM] [Info] Start training from score 0.014668\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2335, number of negative: 2301\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503667 -> initscore=0.014668\n[LightGBM] [Info] Start training from score 0.014668\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2334, number of negative: 2302\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503451 -> initscore=0.013805\n[LightGBM] [Info] Start training from score 0.013805\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2334, number of negative: 2302\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503451 -> initscore=0.013805\n[LightGBM] [Info] Start training from score 0.013805\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2334, number of negative: 2302\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503451 -> initscore=0.013805\n[LightGBM] [Info] Start training from score 0.013805\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2919, number of negative: 2877\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000990 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1869\n[LightGBM] [Info] Number of data points in the train set: 5796, number of used features: 35\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503623 -> initscore=0.014493\n[LightGBM] [Info] Start training from score 0.014493\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2335, number of negative: 2301\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000783 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1867\n[LightGBM] [Info] Number of data points in the train set: 4636, number of used features: 34\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503667 -> initscore=0.014668\n[LightGBM] [Info] Start training from score 0.014668\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2336, number of negative: 2301\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000804 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1869\n[LightGBM] [Info] Number of data points in the train set: 4637, number of used features: 35\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503774 -> initscore=0.015096\n[LightGBM] [Info] Start training from score 0.015096\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2335, number of negative: 2302\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000797 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1869\n[LightGBM] [Info] Number of data points in the train set: 4637, number of used features: 35\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503558 -> initscore=0.014234\n[LightGBM] [Info] Start training from score 0.014234\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2335, number of negative: 2302\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000582 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1869\n[LightGBM] [Info] Number of data points in the train set: 4637, number of used features: 35\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503558 -> initscore=0.014234\n[LightGBM] [Info] Start training from score 0.014234\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 2335, number of negative: 2302\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000922 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1867\n[LightGBM] [Info] Number of data points in the train set: 4637, number of used features: 34\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503558 -> initscore=0.014234\n[LightGBM] [Info] Start training from score 0.014234\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n[LightGBM] [Info] Start training from score 0.014495\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000903 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n[LightGBM] [Info] Start training from score 0.014380\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001299 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n[LightGBM] [Info] Start training from score 0.014380\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n[LightGBM] [Info] Start training from score 0.014380\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 3503, number of negative: 3452\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1873\n[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503666 -> initscore=0.014666\n[LightGBM] [Info] Start training from score 0.014666\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 3503, number of negative: 3452\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000859 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 36\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503666 -> initscore=0.014666\n[LightGBM] [Info] Start training from score 0.014666\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\nFeature names unseen at fit time:\n- PassengerId\n\n  warnings.warn(message, FutureWarning)\n","output_type":"stream"},{"output_type":"error","ename":"ValueError","evalue":"X has 39 features, but RandomForestClassifier is expecting 38 features as input.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn [42], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_df, y_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransported\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Prediksi data submission\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_submission\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_prediction)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_search.py:500\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m    the best found parameters.\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    499\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:607\u001b[0m, in \u001b[0;36mStackingClassifier.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;129m@available_if\u001b[39m(_estimator_has(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params):\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;124;03m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;124;03m        Predicted targets.\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 607\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39minverse_transform(y_pred)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:351\u001b[0m, in \u001b[0;36m_BaseStacking.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m    Predicted targets.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    350\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_estimator_\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:663\u001b[0m, in \u001b[0;36mStackingClassifier.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;124;03m\"\"\"Return class labels or probabilities for X for each estimator.\u001b[39;00m\n\u001b[1;32m    650\u001b[0m \n\u001b[1;32m    651\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m        Prediction outputs for each estimator.\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:276\u001b[0m, in \u001b[0;36m_BaseStacking._transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 276\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(est, meth)(X)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m est, meth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m ]\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concatenate_predictions(X, predictions)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:277\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    276\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m est, meth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m ]\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concatenate_predictions(X, predictions)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:874\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    872\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    873\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 874\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    877\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:605\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    604\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 605\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: X has 39 features, but RandomForestClassifier is expecting 38 features as input."]}],"outputs_reference":"s3:deepnote-cell-outputs-production/0330345f-a300-4550-a6f1-83f3b59283ff","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715878557647,"execution_millis":74,"deepnote_to_be_reexecuted":true,"cell_id":"0bb9fdb59e6342dca4c9479bba13cdf2","deepnote_cell_type":"code"},"source":"X_test","block_group":"6ba3fe8fae0e4a17a2ee589c417848ca","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":38,"row_count":1739,"columns":[{"name":"CryoSleep","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1082},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":657}]}},{"name":"VIP","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1696},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":43}]}},{"name":"RoomService","dtype":"float64","stats":{"unique_count":418,"nan_count":0,"min":"-0.3375298928969419","max":"12.665545282050582","histogram":[{"bin_start":-0.3375298928969419,"bin_end":0.9627776245978106,"count":1577},{"bin_start":0.9627776245978106,"bin_end":2.263085142092563,"count":97},{"bin_start":2.263085142092563,"bin_end":3.5633926595873158,"count":38},{"bin_start":3.5633926595873158,"bin_end":4.863700177082068,"count":15},{"bin_start":4.863700177082068,"bin_end":6.164007694576821,"count":8},{"bin_start":6.164007694576821,"bin_end":7.464315212071573,"count":2},{"bin_start":7.464315212071573,"bin_end":8.764622729566325,"count":1},{"bin_start":8.764622729566325,"bin_end":10.064930247061078,"count":0},{"bin_start":10.064930247061078,"bin_end":11.36523776455583,"count":0},{"bin_start":11.36523776455583,"bin_end":12.665545282050582,"count":1}]}},{"name":"FoodCourt","dtype":"float64","stats":{"unique_count":437,"nan_count":0,"min":"-0.2838651282377854","max":"18.3951838783","histogram":[{"bin_start":-0.2838651282377854,"bin_end":1.5840397724159931,"count":1661},{"bin_start":1.5840397724159931,"bin_end":3.4519446730697716,"count":47},{"bin_start":3.4519446730697716,"bin_end":5.31984957372355,"count":17},{"bin_start":5.31984957372355,"bin_end":7.1877544743773285,"count":7},{"bin_start":7.1877544743773285,"bin_end":9.055659375031107,"count":4},{"bin_start":9.055659375031107,"bin_end":10.923564275684885,"count":1},{"bin_start":10.923564275684885,"bin_end":12.791469176338664,"count":0},{"bin_start":12.791469176338664,"bin_end":14.659374076992442,"count":0},{"bin_start":14.659374076992442,"bin_end":16.52727897764622,"count":1},{"bin_start":16.52727897764622,"bin_end":18.3951838783,"count":1}]}},{"name":"ShoppingMall","dtype":"float64","stats":{"unique_count":374,"nan_count":0,"min":"-0.2873829429551493","max":"20.209895438940528","histogram":[{"bin_start":-0.2873829429551493,"bin_end":1.762344895234418,"count":1684},{"bin_start":1.762344895234418,"bin_end":3.8120727334239852,"count":43},{"bin_start":3.8120727334239852,"bin_end":5.861800571613553,"count":8},{"bin_start":5.861800571613553,"bin_end":7.91152840980312,"count":1},{"bin_start":7.91152840980312,"bin_end":9.961256247992688,"count":0},{"bin_start":9.961256247992688,"bin_end":12.010984086182255,"count":1},{"bin_start":12.010984086182255,"bin_end":14.060711924371821,"count":0},{"bin_start":14.060711924371821,"bin_end":16.11043976256139,"count":1},{"bin_start":16.11043976256139,"bin_end":18.16016760075096,"count":0},{"bin_start":18.16016760075096,"bin_end":20.209895438940528,"count":1}]}},{"name":"Spa","dtype":"float64","stats":{"unique_count":417,"nan_count":0,"min":"-0.2738262777680785","max":"19.63588438583856","histogram":[{"bin_start":-0.2738262777680785,"bin_end":1.7171447885925855,"count":1690},{"bin_start":1.7171447885925855,"bin_end":3.7081158549532494,"count":24},{"bin_start":3.7081158549532494,"bin_end":5.6990869213139135,"count":15},{"bin_start":5.6990869213139135,"bin_end":7.690057987674577,"count":1},{"bin_start":7.690057987674577,"bin_end":9.68102905403524,"count":4},{"bin_start":9.68102905403524,"bin_end":11.672000120395905,"count":2},{"bin_start":11.672000120395905,"bin_end":13.662971186756568,"count":2},{"bin_start":13.662971186756568,"bin_end":15.653942253117233,"count":0},{"bin_start":15.653942253117233,"bin_end":17.644913319477894,"count":0},{"bin_start":17.644913319477894,"bin_end":19.63588438583856,"count":1}]}},{"name":"VRDeck","dtype":"float64","stats":{"unique_count":419,"nan_count":0,"min":"-0.2658309074152016","max":"9.720116155818095","histogram":[{"bin_start":-0.2658309074152016,"bin_end":0.7327637989081281,"count":1608},{"bin_start":0.7327637989081281,"bin_end":1.7313585052314577,"count":69},{"bin_start":1.7313585052314577,"bin_end":2.7299532115547875,"count":24},{"bin_start":2.7299532115547875,"bin_end":3.7285479178781173,"count":13},{"bin_start":3.7285479178781173,"bin_end":4.727142624201447,"count":12},{"bin_start":4.727142624201447,"bin_end":5.725737330524776,"count":2},{"bin_start":5.725737330524776,"bin_end":6.724332036848106,"count":2},{"bin_start":6.724332036848106,"bin_end":7.722926743171436,"count":4},{"bin_start":7.722926743171436,"bin_end":8.721521449494766,"count":2},{"bin_start":8.721521449494766,"bin_end":9.720116155818095,"count":3}]}},{"name":"Expenditure","dtype":"float64","stats":{"unique_count":782,"nan_count":0,"min":"-0.5183569229651437","max":"12.28124717270035","histogram":[{"bin_start":-0.5183569229651437,"bin_end":0.7616034866014056,"count":1556},{"bin_start":0.7616034866014056,"bin_end":2.041563896167955,"count":112},{"bin_start":2.041563896167955,"bin_end":3.321524305734504,"count":35},{"bin_start":3.321524305734504,"bin_end":4.601484715301053,"count":19},{"bin_start":4.601484715301053,"bin_end":5.881445124867604,"count":10},{"bin_start":5.881445124867604,"bin_end":7.161405534434152,"count":3},{"bin_start":7.161405534434152,"bin_end":8.441365944000703,"count":1},{"bin_start":8.441365944000703,"bin_end":9.721326353567251,"count":1},{"bin_start":9.721326353567251,"bin_end":11.0012867631338,"count":1},{"bin_start":11.0012867631338,"bin_end":12.28124717270035,"count":1}]}},{"name":"NoSpending","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":999},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":740}]}},{"name":"Group","dtype":"int64","stats":{"unique_count":1594,"nan_count":0,"min":"1","max":"9280","histogram":[{"bin_start":1,"bin_end":928.9,"count":183},{"bin_start":928.9,"bin_end":1856.8,"count":197},{"bin_start":1856.8,"bin_end":2784.7,"count":149},{"bin_start":2784.7,"bin_end":3712.6,"count":170},{"bin_start":3712.6,"bin_end":4640.5,"count":166},{"bin_start":4640.5,"bin_end":5568.4,"count":171},{"bin_start":5568.4,"bin_end":6496.3,"count":181},{"bin_start":6496.3,"bin_end":7424.2,"count":183},{"bin_start":7424.2,"bin_end":8352.1,"count":149},{"bin_start":8352.1,"bin_end":9280,"count":190}]}},{"name":"GroupSize","dtype":"int64","stats":{"unique_count":8,"nan_count":0,"min":"1","max":"8","histogram":[{"bin_start":1,"bin_end":1.7,"count":974},{"bin_start":1.7,"bin_end":2.4,"count":326},{"bin_start":2.4,"bin_end":3.0999999999999996,"count":194},{"bin_start":3.0999999999999996,"bin_end":3.8,"count":0},{"bin_start":3.8,"bin_end":4.5,"count":89},{"bin_start":4.5,"bin_end":5.199999999999999,"count":55},{"bin_start":5.199999999999999,"bin_end":5.8999999999999995,"count":0},{"bin_start":5.8999999999999995,"bin_end":6.6,"count":36},{"bin_start":6.6,"bin_end":7.3,"count":48},{"bin_start":7.3,"bin_end":8,"count":17}]}},{"name":"Solo","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":765},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":974}]}},{"name":"CabinRegion_1","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":970},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":769}]}},{"name":"CabinRegion_2","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1442},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":297}]}},{"name":"CabinRegion_3","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1569},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":170}]}},{"name":"CabinRegion_4","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1542},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":197}]}},{"name":"CabinRegion_5","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1538},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":201}]}},{"name":"CabinRegion_6","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1651},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":88}]}},{"name":"CabinRegion_7","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1722},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":17}]}},{"name":"FamilySize","dtype":"int64","stats":{"unique_count":20,"nan_count":0,"min":"0","max":"19","histogram":[{"bin_start":0,"bin_end":1.9,"count":49},{"bin_start":1.9,"bin_end":3.8,"count":209},{"bin_start":3.8,"bin_end":5.699999999999999,"count":336},{"bin_start":5.699999999999999,"bin_end":7.6,"count":415},{"bin_start":7.6,"bin_end":9.5,"count":290},{"bin_start":9.5,"bin_end":11.399999999999999,"count":210},{"bin_start":11.399999999999999,"bin_end":13.299999999999999,"count":126},{"bin_start":13.299999999999999,"bin_end":15.2,"count":61},{"bin_start":15.2,"bin_end":17.099999999999998,"count":20},{"bin_start":17.099999999999998,"bin_end":19,"count":23}]}},{"name":"HomePlanet_Earth","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":810},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":929}]}},{"name":"HomePlanet_Europa","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1301},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":438}]}},{"name":"HomePlanet_Mars","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1367},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":372}]}},{"name":"Destination_55 Cancri e","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1387},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":352}]}},{"name":"Destination_PSO J318.5-22","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1577},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":162}]}},{"name":"Destination_TRAPPIST-1e","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":514},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":1225}]}},{"name":"CabinSide_P","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":892},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":847}]}},{"name":"CabinSide_S","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":852},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":887}]}},{"name":"CabinSide_Z","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1734},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":5}]}},{"name":"CabinDeck_A","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1682},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":57}]}},{"name":"CabinDeck_B","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1582},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":157}]}},{"name":"CabinDeck_C","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1583},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":156}]}},{"name":"CabinDeck_D","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1638},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":101}]}},{"name":"CabinDeck_E","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1550},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":189}]}},{"name":"CabinDeck_F","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1174},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":565}]}},{"name":"CabinDeck_G","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1225},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":514}]}},{"name":"CabinDeck_T","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":1739},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"AgeEncoded","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":"1.0","max":"4.0","histogram":[{"bin_start":1,"bin_end":1.3,"count":397},{"bin_start":1.3,"bin_end":1.6,"count":0},{"bin_start":1.6,"bin_end":1.9,"count":0},{"bin_start":1.9,"bin_end":2.2,"count":818},{"bin_start":2.2,"bin_end":2.5,"count":0},{"bin_start":2.5,"bin_end":2.8,"count":0},{"bin_start":2.8,"bin_end":3.1,"count":388},{"bin_start":3.1,"bin_end":3.4,"count":0},{"bin_start":3.4,"bin_end":3.6999999999999997,"count":0},{"bin_start":3.6999999999999997,"bin_end":4,"count":136}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"CryoSleep":0,"VIP":0,"RoomService":0.2939961201420888,"FoodCourt":-0.0652025279197467,"ShoppingMall":0.7731960576260847,"Spa":-0.2711607506353214,"VRDeck":0.6661908184865729,"Expenditure":0.3565986464164972,"NoSpending":0,"Group":337,"GroupSize":3,"Solo":0,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":5,"HomePlanet_Earth":0,"HomePlanet_Europa":0,"HomePlanet_Mars":1,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":0,"CabinSide_S":1,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":1,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":2,"_deepnote_index_column":304},{"CryoSleep":0,"VIP":0,"RoomService":-0.3314720894145531,"FoodCourt":0.2825273952221198,"ShoppingMall":-0.2873829429551493,"Spa":-0.2738262777680785,"VRDeck":-0.2649491460851148,"Expenditure":-0.1950501698887568,"NoSpending":0,"Group":2891,"GroupSize":1,"Solo":1,"CabinRegion_1":0,"CabinRegion_2":1,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":2,"HomePlanet_Earth":1,"HomePlanet_Europa":0,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":0,"CabinSide_S":1,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":1,"CabinDeck_T":0,"AgeEncoded":1,"_deepnote_index_column":2697},{"CryoSleep":1,"VIP":0,"RoomService":-0.3375298928969419,"FoodCourt":-0.2838651282377854,"ShoppingMall":-0.2873829429551493,"Spa":-0.2738262777680785,"VRDeck":-0.2658309074152016,"Expenditure":-0.5183569229651437,"NoSpending":1,"Group":8998,"GroupSize":2,"Solo":0,"CabinRegion_1":0,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":1,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":9,"HomePlanet_Earth":1,"HomePlanet_Europa":0,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":0,"CabinSide_S":1,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":1,"CabinDeck_T":0,"AgeEncoded":3,"_deepnote_index_column":8424},{"CryoSleep":0,"VIP":0,"RoomService":-0.3375298928969419,"FoodCourt":-0.0720944723423783,"ShoppingMall":0.4419742246369926,"Spa":-0.1326706118884168,"VRDeck":-0.2658309074152016,"Expenditure":-0.1865609624094827,"NoSpending":0,"Group":1771,"GroupSize":1,"Solo":1,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":11,"HomePlanet_Earth":1,"HomePlanet_Europa":0,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":1,"CabinSide_S":0,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":1,"CabinDeck_T":0,"AgeEncoded":2,"_deepnote_index_column":1672},{"CryoSleep":1,"VIP":0,"RoomService":-0.3375298928969419,"FoodCourt":-0.2838651282377854,"ShoppingMall":-0.2873829429551493,"Spa":-0.2738262777680785,"VRDeck":-0.2658309074152016,"Expenditure":-0.5183569229651437,"NoSpending":1,"Group":9034,"GroupSize":5,"Solo":0,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":8,"HomePlanet_Earth":0,"HomePlanet_Europa":1,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":1,"CabinSide_S":0,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":1,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":3,"_deepnote_index_column":8458},{"CryoSleep":0,"VIP":0,"RoomService":-0.1391368288487092,"FoodCourt":-0.2838651282377854,"ShoppingMall":1.3519978465868212,"Spa":-0.2729377687238261,"VRDeck":-0.2658309074152016,"Expenditure":-0.1228485517649873,"NoSpending":0,"Group":3706,"GroupSize":2,"Solo":0,"CabinRegion_1":0,"CabinRegion_2":0,"CabinRegion_3":1,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":4,"HomePlanet_Earth":0,"HomePlanet_Europa":0,"HomePlanet_Mars":1,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":1,"CabinSide_S":0,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":1,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":1,"_deepnote_index_column":3438},{"CryoSleep":0,"VIP":0,"RoomService":-0.3345009911557475,"FoodCourt":-0.2838651282377854,"ShoppingMall":-0.2756730801727067,"Spa":-0.2720492596795738,"VRDeck":0.2164925401422918,"Expenditure":-0.3198913913736983,"NoSpending":0,"Group":3614,"GroupSize":1,"Solo":1,"CabinRegion_1":0,"CabinRegion_2":0,"CabinRegion_3":1,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":6,"HomePlanet_Earth":1,"HomePlanet_Europa":0,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":1,"CabinSide_S":0,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":1,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":2,"_deepnote_index_column":3362},{"CryoSleep":0,"VIP":0,"RoomService":-0.3360154420263447,"FoodCourt":0.0087292395230284,"ShoppingMall":-0.2806915927937535,"Spa":-0.2738262777680785,"VRDeck":0.0348497061444058,"Expenditure":-0.2291947774743818,"NoSpending":0,"Group":3476,"GroupSize":4,"Solo":0,"CabinRegion_1":0,"CabinRegion_2":1,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":7,"HomePlanet_Earth":1,"HomePlanet_Europa":0,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":1,"CabinSide_S":0,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":1,"CabinDeck_T":0,"AgeEncoded":2,"_deepnote_index_column":3235},{"CryoSleep":1,"VIP":0,"RoomService":-0.3375298928969419,"FoodCourt":-0.2838651282377854,"ShoppingMall":-0.2873829429551493,"Spa":-0.2738262777680785,"VRDeck":-0.2658309074152016,"Expenditure":-0.5183569229651437,"NoSpending":1,"Group":1210,"GroupSize":2,"Solo":0,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":4,"HomePlanet_Earth":1,"HomePlanet_Europa":0,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":1,"CabinSide_S":0,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":1,"CabinDeck_T":0,"AgeEncoded":3,"_deepnote_index_column":1139},{"CryoSleep":0,"VIP":0,"RoomService":-0.3375298928969419,"FoodCourt":-0.2838651282377854,"ShoppingMall":-0.2873829429551493,"Spa":-0.2738262777680785,"VRDeck":-0.2353837710949045,"Expenditure":-0.5060755676646561,"NoSpending":0,"Group":1289,"GroupSize":2,"Solo":0,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":9,"HomePlanet_Earth":1,"HomePlanet_Europa":0,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":0,"CabinSide_S":1,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":1,"CabinDeck_T":0,"AgeEncoded":1,"_deepnote_index_column":1210}]},"text/plain":"      CryoSleep  VIP  RoomService  FoodCourt  ShoppingMall       Spa  \\\n304           0    0     0.293996  -0.065203      0.773196 -0.271161   \n2697          0    0    -0.331472   0.282527     -0.287383 -0.273826   \n8424          1    0    -0.337530  -0.283865     -0.287383 -0.273826   \n1672          0    0    -0.337530  -0.072094      0.441974 -0.132671   \n8458          1    0    -0.337530  -0.283865     -0.287383 -0.273826   \n...         ...  ...          ...        ...           ...       ...   \n7175          1    0    -0.337530  -0.283865     -0.287383 -0.273826   \n3187          1    0    -0.337530  -0.283865     -0.287383 -0.273826   \n1302          0    0    -0.305726  -0.283865      0.866875 -0.042814   \n5934          1    0    -0.337530  -0.283865     -0.287383 -0.273826   \n6093          0    0    -0.337530  -0.283865     -0.287383  1.330821   \n\n        VRDeck  Expenditure  NoSpending  Group  ...  CabinSide_Z  CabinDeck_A  \\\n304   0.666191     0.356599           0    337  ...            0            0   \n2697 -0.264949    -0.195050           0   2891  ...            0            0   \n8424 -0.265831    -0.518357           1   8998  ...            0            0   \n1672 -0.265831    -0.186561           0   1771  ...            0            0   \n8458 -0.265831    -0.518357           1   9034  ...            0            0   \n...        ...          ...         ...    ...  ...          ...          ...   \n7175 -0.265831    -0.518357           1   7656  ...            0            0   \n3187 -0.265831    -0.518357           1   3437  ...            0            0   \n1302 -0.261422    -0.171220           0   1384  ...            0            0   \n5934 -0.265831    -0.518357           1   6300  ...            0            0   \n6093 -0.265831     0.123989           0   6442  ...            0            0   \n\n      CabinDeck_B  CabinDeck_C  CabinDeck_D  CabinDeck_E  CabinDeck_F  \\\n304             0            0            0            0            1   \n2697            0            0            0            0            0   \n8424            0            0            0            0            0   \n1672            0            0            0            0            0   \n8458            0            0            1            0            0   \n...           ...          ...          ...          ...          ...   \n7175            0            0            0            0            0   \n3187            0            0            0            0            0   \n1302            0            0            0            1            0   \n5934            0            0            0            0            1   \n6093            0            0            0            0            0   \n\n      CabinDeck_G  CabinDeck_T  AgeEncoded  \n304             0            0         2.0  \n2697            1            0         1.0  \n8424            1            0         3.0  \n1672            1            0         2.0  \n8458            0            0         3.0  \n...           ...          ...         ...  \n7175            1            0         1.0  \n3187            1            0         1.0  \n1302            0            0         1.0  \n5934            0            0         3.0  \n6093            1            0         1.0  \n\n[1739 rows x 38 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CryoSleep</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Expenditure</th>\n      <th>NoSpending</th>\n      <th>Group</th>\n      <th>...</th>\n      <th>CabinSide_Z</th>\n      <th>CabinDeck_A</th>\n      <th>CabinDeck_B</th>\n      <th>CabinDeck_C</th>\n      <th>CabinDeck_D</th>\n      <th>CabinDeck_E</th>\n      <th>CabinDeck_F</th>\n      <th>CabinDeck_G</th>\n      <th>CabinDeck_T</th>\n      <th>AgeEncoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>304</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.293996</td>\n      <td>-0.065203</td>\n      <td>0.773196</td>\n      <td>-0.271161</td>\n      <td>0.666191</td>\n      <td>0.356599</td>\n      <td>0</td>\n      <td>337</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2697</th>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.331472</td>\n      <td>0.282527</td>\n      <td>-0.287383</td>\n      <td>-0.273826</td>\n      <td>-0.264949</td>\n      <td>-0.195050</td>\n      <td>0</td>\n      <td>2891</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8424</th>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.337530</td>\n      <td>-0.283865</td>\n      <td>-0.287383</td>\n      <td>-0.273826</td>\n      <td>-0.265831</td>\n      <td>-0.518357</td>\n      <td>1</td>\n      <td>8998</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1672</th>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.337530</td>\n      <td>-0.072094</td>\n      <td>0.441974</td>\n      <td>-0.132671</td>\n      <td>-0.265831</td>\n      <td>-0.186561</td>\n      <td>0</td>\n      <td>1771</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>8458</th>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.337530</td>\n      <td>-0.283865</td>\n      <td>-0.287383</td>\n      <td>-0.273826</td>\n      <td>-0.265831</td>\n      <td>-0.518357</td>\n      <td>1</td>\n      <td>9034</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7175</th>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.337530</td>\n      <td>-0.283865</td>\n      <td>-0.287383</td>\n      <td>-0.273826</td>\n      <td>-0.265831</td>\n      <td>-0.518357</td>\n      <td>1</td>\n      <td>7656</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3187</th>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.337530</td>\n      <td>-0.283865</td>\n      <td>-0.287383</td>\n      <td>-0.273826</td>\n      <td>-0.265831</td>\n      <td>-0.518357</td>\n      <td>1</td>\n      <td>3437</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1302</th>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.305726</td>\n      <td>-0.283865</td>\n      <td>0.866875</td>\n      <td>-0.042814</td>\n      <td>-0.261422</td>\n      <td>-0.171220</td>\n      <td>0</td>\n      <td>1384</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5934</th>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.337530</td>\n      <td>-0.283865</td>\n      <td>-0.287383</td>\n      <td>-0.273826</td>\n      <td>-0.265831</td>\n      <td>-0.518357</td>\n      <td>1</td>\n      <td>6300</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>6093</th>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.337530</td>\n      <td>-0.283865</td>\n      <td>-0.287383</td>\n      <td>1.330821</td>\n      <td>-0.265831</td>\n      <td>0.123989</td>\n      <td>0</td>\n      <td>6442</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1739 rows × 38 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/a6dd9c35-fc2f-41f8-9e02-5a372c1f3b72","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715876975807,"execution_millis":215,"deepnote_to_be_reexecuted":true,"cell_id":"4e7e4a6273c24f158108111916dc4c0a","deepnote_cell_type":"code"},"source":"submission_dict = {'PassengerId':X_submission['PassengerId'], 'Transported':y_pred.astype('bool')}\nsubmission_dict = pd.DataFrame(submission_dict)\nsubmission_dict","block_group":"8631fd94f9444f55b802e1906d5a21f9","execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"array length 33007 does not match index length 4277","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn [17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m submission_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m'\u001b[39m:X_submission[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransported\u001b[39m\u001b[38;5;124m'\u001b[39m:y_pred\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m'\u001b[39m)}\n\u001b[0;32m----> 2\u001b[0m submission_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmission_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m submission_dict\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/internals/construction.py:690\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m    686\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    687\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m         )\n\u001b[0;32m--> 690\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(lengths[\u001b[38;5;241m0\u001b[39m])\n","\u001b[0;31mValueError\u001b[0m: array length 33007 does not match index length 4277"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/0ebc8901-4c32-489e-af7e-98dbb7ea7996","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715758957859,"execution_millis":567,"deepnote_to_be_reexecuted":true,"cell_id":"c79e0aaeeeb049999fc11ca775828929","deepnote_cell_type":"code"},"source":"submission_dict.to_csv('spaceship_112.csv', index=False)","block_group":"9f2e6f9d492e41deb8e6c451c49745cf","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715032504876,"execution_millis":1026,"deepnote_to_be_reexecuted":true,"cell_id":"1b85504a05af4193ab02010d93a64a1f","deepnote_cell_type":"code"},"source":"X_df = pd.read_csv('preprocessedbankchurn_train.csv')\nX_df.drop(\"Exited\", axis=1, inplace=True)\ny_df = pd.read_csv('preprocessedbankchurn_train.csv')\ny_df = y_df.loc[:, ['Exited']]\nX_submission = pd.read_csv('preprocessedbankchurn_test.csv')\n\nX_df.info()","block_group":"9acd7481bdec43f3ba43972876e9aaa0","execution_count":null,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 165034 entries, 0 to 165033\nData columns (total 17 columns):\n #   Column               Non-Null Count   Dtype  \n---  ------               --------------   -----  \n 0   id                   165034 non-null  int64  \n 1   CustomerId           165034 non-null  int64  \n 2   CreditScore          165034 non-null  int64  \n 3   Age                  165034 non-null  float64\n 4   Tenure               165034 non-null  int64  \n 5   Balance              165034 non-null  float64\n 6   NumOfProducts        165034 non-null  int64  \n 7   HasCrCard            165034 non-null  float64\n 8   IsActiveMember       165034 non-null  float64\n 9   EstimatedSalary      165034 non-null  float64\n 10  France               165034 non-null  int64  \n 11  Germany              165034 non-null  int64  \n 12  Spain                165034 non-null  int64  \n 13  Female               165034 non-null  int64  \n 14  Male                 165034 non-null  int64  \n 15  ExitedfamilySize     165034 non-null  float64\n 16  NotExitedfamilySize  165034 non-null  float64\ndtypes: float64(7), int64(10)\nmemory usage: 21.4 MB\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/476eb684-06e6-4c9e-8344-f3bcb97fa349","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715032505908,"execution_millis":372,"deepnote_to_be_reexecuted":true,"cell_id":"98c5ebb50d744d9686c00e0d4caaab8a","deepnote_cell_type":"code"},"source":"X_submission.info()","block_group":"91575ba172d8481e916462e6b5fcda67","execution_count":null,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 110023 entries, 0 to 110022\nData columns (total 17 columns):\n #   Column               Non-Null Count   Dtype  \n---  ------               --------------   -----  \n 0   id                   110023 non-null  int64  \n 1   CustomerId           110023 non-null  int64  \n 2   CreditScore          110023 non-null  int64  \n 3   Age                  110023 non-null  float64\n 4   Tenure               110023 non-null  int64  \n 5   Balance              110023 non-null  float64\n 6   NumOfProducts        110023 non-null  int64  \n 7   HasCrCard            110023 non-null  float64\n 8   IsActiveMember       110023 non-null  float64\n 9   EstimatedSalary      110023 non-null  float64\n 10  France               110023 non-null  int64  \n 11  Germany              110023 non-null  int64  \n 12  Spain                110023 non-null  int64  \n 13  Female               110023 non-null  int64  \n 14  Male                 110023 non-null  int64  \n 15  ExitedfamilySize     110023 non-null  float64\n 16  NotExitedfamilySize  110023 non-null  float64\ndtypes: float64(7), int64(10)\nmemory usage: 14.3 MB\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/14df34f4-61f6-4ce2-af28-ef3054bab200","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715032505938,"execution_millis":342,"deepnote_to_be_reexecuted":true,"cell_id":"4d651235f2d246e2a252a97d9d2c3449","deepnote_cell_type":"code"},"source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=42)\n# Mengubah target menjadi 1D array\ny_train = y_train['Exited'].values\ny_test = y_test['Exited'].values\n\n\n# Base estimator\nbase_estimator = DecisionTreeClassifier(max_depth=1)\n\n# Membuat pipeline\npipeline = Pipeline([\n    ('scaler', StandardScaler()),  # Normalisasi data\n    ('classifier', AdaBoostClassifier(base_estimator=base_estimator))\n])\n\nparameters = {\n    'classifier__n_estimators': [50, 100, 200],\n    'classifier__learning_rate': [0.01, 0.1, 1]\n}\n\n# Menggunakan StratifiedKFold untuk handling imbalanced data\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)","block_group":"f3e98e79ef544fb98587f50a6297debd","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0d60f0f6a1ed426fa543bd683391a970","deepnote_cell_type":"text-cell-h1"},"source":"# Model Training","block_group":"e01f12f006324577a8685ffcb2e53c45"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715032505974,"execution_millis":317667,"deepnote_to_be_reexecuted":true,"cell_id":"c347478285274198a11059886968cdcb","deepnote_cell_type":"code"},"source":"# Membuat GridSearchCV\ngrid_search = GridSearchCV(pipeline, parameters, cv=cv, scoring='accuracy', verbose=1)\ngrid_search.fit(X_train, y_train)\n\n#Evaluasi model\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_test)\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Accuracy on test set:\", accuracy_score(y_test, y_pred))","block_group":"ffa1a5a6dc0742f6a823ee9eafca1c28","execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 10 folds for each of 9 candidates, totalling 90 fits\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Membuat GridSearchCV\u001b[39;00m\n\u001b[1;32m      2\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, parameters, cv\u001b[38;5;241m=\u001b[39mcv, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#Evaluasi model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:506\u001b[0m, in \u001b[0;36mAdaBoostClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlgorithm must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAMME\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:160\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    156\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iboost \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators):\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:568\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \n\u001b[1;32m    531\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost_real\u001b[49m\u001b[43m(\u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:577\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m--> 577\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m y_predict_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/tree/_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"outputs_reference":"s3:deepnote-cell-outputs-production/c28f0a59-a546-4933-a60d-1bb23899e176","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715027000161,"execution_millis":862,"deepnote_to_be_reexecuted":true,"cell_id":"ecce8794affe41a28854a4731c0b055f","deepnote_cell_type":"code"},"source":"# Evaluasi pada validation set\ny_pred = grid_search.predict(X_test)\nprint(classification_report(y_test, y_pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))","block_group":"77ebd873ac4449b9bc8a4851f956eb72","execution_count":null,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.89      0.95      0.92     26052\n           1       0.75      0.56      0.64      6955\n\n    accuracy                           0.87     33007\n   macro avg       0.82      0.76      0.78     33007\nweighted avg       0.86      0.87      0.86     33007\n\nConfusion Matrix:\n[[24755  1297]\n [ 3028  3927]]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/afbe79e8-40d7-42ee-a79e-01dbda2b56fb","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715027001038,"execution_millis":957,"deepnote_to_be_reexecuted":true,"cell_id":"ebc0a6dcf6a7498dba975d1a0b82272b","deepnote_cell_type":"code"},"source":"best_ada = grid_search.best_estimator_\ny_pred_light = best_ada.predict(X_test)\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_light))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_light))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_light))","block_group":"4688de50a0874df890980b8a72f907a7","execution_count":null,"outputs":[{"name":"stdout","text":"Best parameters: {'classifier__learning_rate': 1, 'classifier__n_estimators': 200}\nAccuracy: 0.8689671887781379\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.89      0.95      0.92     26052\n           1       0.75      0.56      0.64      6955\n\n    accuracy                           0.87     33007\n   macro avg       0.82      0.76      0.78     33007\nweighted avg       0.86      0.87      0.86     33007\n\nConfusion Matrix:\n [[24755  1297]\n [ 3028  3927]]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/b47a81c9-18f6-45ad-81ca-2ed35092cac6","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c240899462784636823cf67e7b67746b","deepnote_cell_type":"text-cell-h1"},"source":"# Submission Prediction","block_group":"4c856cb090fc4ca8847589c39997e4a2"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715027001999,"execution_millis":248,"deepnote_to_be_reexecuted":true,"cell_id":"b5c65d9ba8e047849893250db8930167","deepnote_cell_type":"code"},"source":"X_submission.info()","block_group":"ba8a558937cc4653971c76f73c5a05ab","execution_count":null,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 110023 entries, 0 to 110022\nData columns (total 17 columns):\n #   Column               Non-Null Count   Dtype  \n---  ------               --------------   -----  \n 0   id                   110023 non-null  int64  \n 1   CustomerId           110023 non-null  int64  \n 2   CreditScore          110023 non-null  int64  \n 3   Age                  110023 non-null  float64\n 4   Tenure               110023 non-null  int64  \n 5   Balance              110023 non-null  float64\n 6   NumOfProducts        110023 non-null  int64  \n 7   HasCrCard            110023 non-null  float64\n 8   IsActiveMember       110023 non-null  float64\n 9   EstimatedSalary      110023 non-null  float64\n 10  France               110023 non-null  int64  \n 11  Germany              110023 non-null  int64  \n 12  Spain                110023 non-null  int64  \n 13  Female               110023 non-null  int64  \n 14  Male                 110023 non-null  int64  \n 15  ExitedfamilySize     110023 non-null  float64\n 16  NotExitedfamilySize  110023 non-null  float64\ndtypes: float64(7), int64(10)\nmemory usage: 14.3 MB\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/f79498fd-e570-41c1-b08c-26d8248358ed","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715027002017,"execution_millis":231,"deepnote_to_be_reexecuted":true,"cell_id":"018ccf8808af431392cd2d7cd0e3d9c6","deepnote_cell_type":"code"},"source":"X_train.info()","block_group":"9e9b41c78fb6488ca7f85e327ff652d8","execution_count":null,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 132027 entries, 149380 to 121958\nData columns (total 17 columns):\n #   Column               Non-Null Count   Dtype  \n---  ------               --------------   -----  \n 0   id                   132027 non-null  int64  \n 1   CustomerId           132027 non-null  int64  \n 2   CreditScore          132027 non-null  int64  \n 3   Age                  132027 non-null  float64\n 4   Tenure               132027 non-null  int64  \n 5   Balance              132027 non-null  float64\n 6   NumOfProducts        132027 non-null  int64  \n 7   HasCrCard            132027 non-null  float64\n 8   IsActiveMember       132027 non-null  float64\n 9   EstimatedSalary      132027 non-null  float64\n 10  France               132027 non-null  int64  \n 11  Germany              132027 non-null  int64  \n 12  Spain                132027 non-null  int64  \n 13  Female               132027 non-null  int64  \n 14  Male                 132027 non-null  int64  \n 15  ExitedfamilySize     132027 non-null  float64\n 16  NotExitedfamilySize  132027 non-null  float64\ndtypes: float64(7), int64(10)\nmemory usage: 18.1 MB\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/e241eb72-0cf8-4d2c-a815-362c95c79e72","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715029630353,"execution_millis":1733102,"deepnote_to_be_reexecuted":true,"cell_id":"8b17dd9894344b59898e17b91987b22a","deepnote_cell_type":"code"},"source":"# For training, we use ALL data from spaceship_train_X_v2.csv and spaceship_train_y.csv\ngrid_search.fit(X_df, y_df['Exited'].values)\n# Prediksi data submission\ny_prediction = grid_search.predict(X_submission)\nprint(y_prediction)\n","block_group":"51e9e9b1a74b47e3beec7c41ad94151c","execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 10 folds for each of 9 candidates, totalling 90 fits\n[0 1 0 ... 0 0 0]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/8b2ac23f-7377-4797-a530-55030f20e408","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715028721277,"execution_millis":178,"deepnote_to_be_reexecuted":true,"cell_id":"131401ca70dd4a239cdd32ec8afcc6f3","deepnote_cell_type":"code"},"source":"X_submission.info()","block_group":"e5126cdabfd546f1a59d03b6b2bb9e4d","execution_count":null,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 110023 entries, 0 to 110022\nData columns (total 17 columns):\n #   Column               Non-Null Count   Dtype  \n---  ------               --------------   -----  \n 0   id                   110023 non-null  int64  \n 1   CustomerId           110023 non-null  int64  \n 2   CreditScore          110023 non-null  int64  \n 3   Age                  110023 non-null  float64\n 4   Tenure               110023 non-null  int64  \n 5   Balance              110023 non-null  float64\n 6   NumOfProducts        110023 non-null  int64  \n 7   HasCrCard            110023 non-null  float64\n 8   IsActiveMember       110023 non-null  float64\n 9   EstimatedSalary      110023 non-null  float64\n 10  France               110023 non-null  int64  \n 11  Germany              110023 non-null  int64  \n 12  Spain                110023 non-null  int64  \n 13  Female               110023 non-null  int64  \n 14  Male                 110023 non-null  int64  \n 15  ExitedfamilySize     110023 non-null  float64\n 16  NotExitedfamilySize  110023 non-null  float64\ndtypes: float64(7), int64(10)\nmemory usage: 14.3 MB\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/fef7fc08-981f-41ca-9c8e-7a8764058d13","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715028721278,"execution_millis":177,"deepnote_to_be_reexecuted":true,"cell_id":"a772a8d64d394f95bae464e0489b5a1a","deepnote_cell_type":"code"},"source":"X_train.info()","block_group":"e27540986b294c2e9e761901e7387d2c","execution_count":null,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 132027 entries, 149380 to 121958\nData columns (total 17 columns):\n #   Column               Non-Null Count   Dtype  \n---  ------               --------------   -----  \n 0   id                   132027 non-null  int64  \n 1   CustomerId           132027 non-null  int64  \n 2   CreditScore          132027 non-null  int64  \n 3   Age                  132027 non-null  float64\n 4   Tenure               132027 non-null  int64  \n 5   Balance              132027 non-null  float64\n 6   NumOfProducts        132027 non-null  int64  \n 7   HasCrCard            132027 non-null  float64\n 8   IsActiveMember       132027 non-null  float64\n 9   EstimatedSalary      132027 non-null  float64\n 10  France               132027 non-null  int64  \n 11  Germany              132027 non-null  int64  \n 12  Spain                132027 non-null  int64  \n 13  Female               132027 non-null  int64  \n 14  Male                 132027 non-null  int64  \n 15  ExitedfamilySize     132027 non-null  float64\n 16  NotExitedfamilySize  132027 non-null  float64\ndtypes: float64(7), int64(10)\nmemory usage: 18.1 MB\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/9e44fc57-a10f-44af-a7b8-f404664eab1b","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715031363457,"execution_millis":232,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":100,"pageIndex":0},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":true,"cell_id":"d8b33f18c6f74d6ea6e6b8a515b53f19","deepnote_cell_type":"code"},"source":"submission_dict = {'id':X_submission['id'], 'Exited':y_prediction}\nsubmission_dict = pd.DataFrame(submission_dict)\nsubmission_dict","block_group":"dd269131f3a14a0d86bd4f70d52f78ba","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":2,"row_count":110023,"columns":[{"name":"id","dtype":"int64"},{"name":"Exited","dtype":"int64"},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"id":165034,"Exited":0,"_deepnote_index_column":0},{"id":165035,"Exited":1,"_deepnote_index_column":1},{"id":165036,"Exited":0,"_deepnote_index_column":2},{"id":165037,"Exited":0,"_deepnote_index_column":3},{"id":165038,"Exited":0,"_deepnote_index_column":4},{"id":165039,"Exited":0,"_deepnote_index_column":5},{"id":165040,"Exited":0,"_deepnote_index_column":6},{"id":165041,"Exited":0,"_deepnote_index_column":7},{"id":165042,"Exited":1,"_deepnote_index_column":8},{"id":165043,"Exited":0,"_deepnote_index_column":9},{"id":165044,"Exited":0,"_deepnote_index_column":10},{"id":165045,"Exited":0,"_deepnote_index_column":11},{"id":165046,"Exited":0,"_deepnote_index_column":12},{"id":165047,"Exited":0,"_deepnote_index_column":13},{"id":165048,"Exited":0,"_deepnote_index_column":14},{"id":165049,"Exited":0,"_deepnote_index_column":15},{"id":165050,"Exited":0,"_deepnote_index_column":16},{"id":165051,"Exited":0,"_deepnote_index_column":17},{"id":165052,"Exited":0,"_deepnote_index_column":18},{"id":165053,"Exited":0,"_deepnote_index_column":19},{"id":165054,"Exited":0,"_deepnote_index_column":20},{"id":165055,"Exited":0,"_deepnote_index_column":21},{"id":165056,"Exited":0,"_deepnote_index_column":22},{"id":165057,"Exited":0,"_deepnote_index_column":23},{"id":165058,"Exited":0,"_deepnote_index_column":24},{"id":165059,"Exited":0,"_deepnote_index_column":25},{"id":165060,"Exited":1,"_deepnote_index_column":26},{"id":165061,"Exited":0,"_deepnote_index_column":27},{"id":165062,"Exited":0,"_deepnote_index_column":28},{"id":165063,"Exited":0,"_deepnote_index_column":29},{"id":165064,"Exited":0,"_deepnote_index_column":30},{"id":165065,"Exited":0,"_deepnote_index_column":31},{"id":165066,"Exited":0,"_deepnote_index_column":32},{"id":165067,"Exited":0,"_deepnote_index_column":33},{"id":165068,"Exited":0,"_deepnote_index_column":34},{"id":165069,"Exited":0,"_deepnote_index_column":35},{"id":165070,"Exited":1,"_deepnote_index_column":36},{"id":165071,"Exited":0,"_deepnote_index_column":37},{"id":165072,"Exited":0,"_deepnote_index_column":38},{"id":165073,"Exited":1,"_deepnote_index_column":39},{"id":165074,"Exited":0,"_deepnote_index_column":40},{"id":165075,"Exited":0,"_deepnote_index_column":41},{"id":165076,"Exited":0,"_deepnote_index_column":42},{"id":165077,"Exited":0,"_deepnote_index_column":43},{"id":165078,"Exited":0,"_deepnote_index_column":44},{"id":165079,"Exited":0,"_deepnote_index_column":45},{"id":165080,"Exited":0,"_deepnote_index_column":46},{"id":165081,"Exited":0,"_deepnote_index_column":47},{"id":165082,"Exited":0,"_deepnote_index_column":48},{"id":165083,"Exited":0,"_deepnote_index_column":49},{"id":165084,"Exited":0,"_deepnote_index_column":50},{"id":165085,"Exited":0,"_deepnote_index_column":51},{"id":165086,"Exited":0,"_deepnote_index_column":52},{"id":165087,"Exited":0,"_deepnote_index_column":53},{"id":165088,"Exited":0,"_deepnote_index_column":54},{"id":165089,"Exited":0,"_deepnote_index_column":55},{"id":165090,"Exited":0,"_deepnote_index_column":56},{"id":165091,"Exited":0,"_deepnote_index_column":57},{"id":165092,"Exited":0,"_deepnote_index_column":58},{"id":165093,"Exited":0,"_deepnote_index_column":59},{"id":165094,"Exited":0,"_deepnote_index_column":60},{"id":165095,"Exited":0,"_deepnote_index_column":61},{"id":165096,"Exited":0,"_deepnote_index_column":62},{"id":165097,"Exited":0,"_deepnote_index_column":63},{"id":165098,"Exited":0,"_deepnote_index_column":64},{"id":165099,"Exited":0,"_deepnote_index_column":65},{"id":165100,"Exited":1,"_deepnote_index_column":66},{"id":165101,"Exited":0,"_deepnote_index_column":67},{"id":165102,"Exited":0,"_deepnote_index_column":68},{"id":165103,"Exited":0,"_deepnote_index_column":69},{"id":165104,"Exited":0,"_deepnote_index_column":70},{"id":165105,"Exited":0,"_deepnote_index_column":71},{"id":165106,"Exited":0,"_deepnote_index_column":72},{"id":165107,"Exited":0,"_deepnote_index_column":73},{"id":165108,"Exited":0,"_deepnote_index_column":74},{"id":165109,"Exited":0,"_deepnote_index_column":75},{"id":165110,"Exited":0,"_deepnote_index_column":76},{"id":165111,"Exited":0,"_deepnote_index_column":77},{"id":165112,"Exited":0,"_deepnote_index_column":78},{"id":165113,"Exited":0,"_deepnote_index_column":79},{"id":165114,"Exited":0,"_deepnote_index_column":80},{"id":165115,"Exited":0,"_deepnote_index_column":81},{"id":165116,"Exited":0,"_deepnote_index_column":82},{"id":165117,"Exited":0,"_deepnote_index_column":83},{"id":165118,"Exited":0,"_deepnote_index_column":84},{"id":165119,"Exited":0,"_deepnote_index_column":85},{"id":165120,"Exited":0,"_deepnote_index_column":86},{"id":165121,"Exited":0,"_deepnote_index_column":87},{"id":165122,"Exited":0,"_deepnote_index_column":88},{"id":165123,"Exited":0,"_deepnote_index_column":89},{"id":165124,"Exited":0,"_deepnote_index_column":90},{"id":165125,"Exited":0,"_deepnote_index_column":91},{"id":165126,"Exited":0,"_deepnote_index_column":92},{"id":165127,"Exited":0,"_deepnote_index_column":93},{"id":165128,"Exited":0,"_deepnote_index_column":94},{"id":165129,"Exited":0,"_deepnote_index_column":95},{"id":165130,"Exited":1,"_deepnote_index_column":96},{"id":165131,"Exited":0,"_deepnote_index_column":97},{"id":165132,"Exited":0,"_deepnote_index_column":98},{"id":165133,"Exited":0,"_deepnote_index_column":99}]},"text/plain":"            id  Exited\n0       165034       0\n1       165035       1\n2       165036       0\n3       165037       0\n4       165038       0\n...        ...     ...\n110018  275052       0\n110019  275053       0\n110020  275054       0\n110021  275055       0\n110022  275056       0\n\n[110023 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>165034</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>165035</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>165036</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>165037</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>165038</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>110018</th>\n      <td>275052</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110019</th>\n      <td>275053</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110020</th>\n      <td>275054</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110021</th>\n      <td>275055</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110022</th>\n      <td>275056</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>110023 rows × 2 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/7ce954e5-0b38-4bea-9e30-b8205acb1f9a","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"84be499202b94cb894e70434f2f244a9","deepnote_cell_type":"text-cell-h2"},"source":"## Export CSV","block_group":"11179e1880944debabb23367b2d4f7f0"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715054203342,"execution_millis":2587,"deepnote_to_be_reexecuted":true,"cell_id":"7e5c7e25526d42a38cf95d1b65230b62","deepnote_cell_type":"code"},"source":"submission_dict.to_csv('bankChurn_adaboost3.csv', index=False)","block_group":"af3684a41e194ff4ba4e0fbc07d01dd3","execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'dict' object has no attribute 'to_csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msubmission_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbankChurn_adaboost3.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to_csv'"]}],"outputs_reference":"dbtable:cell_outputs/c6317389-a4d5-4e22-8bb4-1ab0bab74138","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=2a79941c-6614-47fe-9427-0e9f23998893' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2024-05-19T20:15:11.508Z"},"deepnote_notebook_id":"cef17c0e35834f2d9555ba2c101c9da8","deepnote_execution_queue":[]}}
{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"ada47ff0f8614f46811013c5d363eab3","deepnote_cell_type":"text-cell-h1"},"source":"# Spaceship Lightgbm Submission","block_group":"082f42d739ae4c33b25722d4d688de17"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1716121350581,"execution_millis":14065,"deepnote_to_be_reexecuted":false,"cell_id":"1122caae9a964691bab58c8a34e479ef","deepnote_cell_type":"code"},"source":"!pip install lightgbm==4.3.0","block_group":"ed00792b3cca4a8e878c8e325bb73c4b","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting lightgbm==4.3.0\n  Downloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl (3.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from lightgbm==4.3.0) (1.9.3)\nRequirement already satisfied: numpy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from lightgbm==4.3.0) (1.23.4)\nInstalling collected packages: lightgbm\nSuccessfully installed lightgbm-4.3.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/4ee1ede5-ed55-497a-a914-ef1289911789","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1716121366636,"execution_millis":19704,"deepnote_to_be_reexecuted":false,"cell_id":"7f8e717f47d84290866e8e3992366110","deepnote_cell_type":"code"},"source":"#Visualisasi\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay\nfrom lightgbm import LGBMClassifier\nfrom sklearn.pipeline import Pipeline\n\n# Memuat data\nX_df = pd.read_csv('spaceship_train_X_v2.csv')\ny_df = pd.read_csv('spaceship_train_y.csv')\nX_submission = pd.read_csv('spaceship_test_X_v2.csv')\n\ny_df.drop('Unnamed: 0', axis=1, inplace=True)\n\n# Standarisasi data\nscaler = StandardScaler()\nX_df_scaled = scaler.fit_transform(X_df)\nX_submission_scaled = scaler.transform(X_submission)\n\n# Membagi data menjadi train dan test\nX_train, X_test, y_train, y_test = train_test_split(X_df_scaled, y_df, stratify=y_df, test_size=0.1, train_size=0.9, random_state=1)\n\n# Mengubah target menjadi 1D array\ny_train = y_train['Transported'].values\ny_test = y_test['Transported'].values\n\n# Membuat pipeline\npipeline = Pipeline([\n    ('scaler', MinMaxScaler()),\n    ('classifier', LGBMClassifier(random_state=42))\n])\n\nparam_grid = {\n    'classifier__n_estimators': [500],\n    'classifier__max_depth': [10],\n    'classifier__learning_rate': [0.01],\n    'classifier__subsample': [0.8],\n    'classifier__colsample_bytree': [1]\n}\n\n# Menggunakan StratifiedKFold untuk handling imbalanced data\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\n# Membuat GridSearchCV dengan cv yang lebih robust\ngrid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='accuracy', verbose=1)\ngrid_search.fit(X_train, y_train)\n\n# Menampilkan parameter terbaik dan skor\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n\n# Prediksi menggunakan model terbaik\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_test)\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\ndisp.plot()\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# ROC Curve\ny_pred_proba = best_model.predict_proba(X_test)[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","block_group":"49f56c395fd84d3a91f89f901e412d60","execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 10 folds for each of 1 candidates, totalling 10 fits\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3546, number of negative: 3494\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001541 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7040, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503693 -> initscore=0.014773\n[LightGBM] [Info] Start training from score 0.014773\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3546, number of negative: 3494\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001510 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7040, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503693 -> initscore=0.014773\n[LightGBM] [Info] Start training from score 0.014773\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3546, number of negative: 3494\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001534 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7040, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503693 -> initscore=0.014773\n[LightGBM] [Info] Start training from score 0.014773\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3546, number of negative: 3495\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001231 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7041, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503622 -> initscore=0.014487\n[LightGBM] [Info] Start training from score 0.014487\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3546, number of negative: 3495\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000975 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7041, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503622 -> initscore=0.014487\n[LightGBM] [Info] Start training from score 0.014487\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3546, number of negative: 3495\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001240 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7041, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503622 -> initscore=0.014487\n[LightGBM] [Info] Start training from score 0.014487\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3546, number of negative: 3495\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000918 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7041, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503622 -> initscore=0.014487\n[LightGBM] [Info] Start training from score 0.014487\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3546, number of negative: 3495\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001542 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7041, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503622 -> initscore=0.014487\n[LightGBM] [Info] Start training from score 0.014487\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3546, number of negative: 3495\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001233 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7041, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503622 -> initscore=0.014487\n[LightGBM] [Info] Start training from score 0.014487\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3546, number of negative: 3495\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7041, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503622 -> initscore=0.014487\n[LightGBM] [Info] Start training from score 0.014487\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001749 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\nBest parameters: {'classifier__colsample_bytree': 1, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 10, 'classifier__n_estimators': 500, 'classifier__subsample': 0.8}\nBest cross-validation score: 0.81\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","output_type":"stream"},{"data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{"image/png":{"width":507,"height":455}},"output_type":"display_data"},{"name":"stdout","text":"[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","output_type":"stream"},{"data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{"image/png":{"width":578,"height":455}},"output_type":"display_data"}],"outputs_reference":"s3:deepnote-cell-outputs-production/45fe735f-d7de-46b5-a419-333984c03ae7","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193622612,"execution_millis":455,"deepnote_to_be_reexecuted":false,"cell_id":"2127821e185e42798bce30173a0528aa","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler","block_group":"6d67ae98cbb84c27b03fe6f9075b0099","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"f1a1d4b5ed1444aba6a3cd0c78e0e92a","deepnote_cell_type":"text-cell-h1"},"source":"# Bring the Data In","block_group":"0c79d79c638f4ac7a0e36c426c763934"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193623070,"execution_millis":376,"deepnote_to_be_reexecuted":false,"cell_id":"5b21978da1684fba8256cad9edd598dd","deepnote_cell_type":"code"},"source":"X_df = pd.read_csv('spaceship_train_X_v2.csv')\ny_df = pd.read_csv('spaceship_train_y.csv')\nX_submission = pd.read_csv('spaceship_test_X_v2.csv')\n\ny_df.drop('Unnamed: 0', axis=1, inplace=True)\nX_df.head()","block_group":"9acd7481bdec43f3ba43972876e9aaa0","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":39,"row_count":5,"columns":[{"name":"PassengerId","dtype":"object","stats":{"unique_count":5,"nan_count":0,"categories":[{"name":"0001_01","count":1},{"name":"0002_01","count":1},{"name":"3 others","count":3}]}},{"name":"CryoSleep","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"VIP","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":1}]}},{"name":"RoomService","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":"-0.3375298928969419","max":"0.1213487208940084","histogram":[{"bin_start":-0.3375298928969419,"bin_end":-0.2916420315178469,"count":2},{"bin_start":-0.2916420315178469,"bin_end":-0.24575417013875184,"count":1},{"bin_start":-0.24575417013875184,"bin_end":-0.19986630875965683,"count":0},{"bin_start":-0.19986630875965683,"bin_end":-0.1539784473805618,"count":1},{"bin_start":-0.1539784473805618,"bin_end":-0.10809058600146676,"count":0},{"bin_start":-0.10809058600146676,"bin_end":-0.06220272462237175,"count":0},{"bin_start":-0.06220272462237175,"bin_end":-0.01631486324327669,"count":0},{"bin_start":-0.01631486324327669,"bin_end":0.029572998135818318,"count":0},{"bin_start":0.029572998135818318,"bin_end":0.07546085951491333,"count":0},{"bin_start":0.07546085951491333,"bin_end":0.1213487208940084,"count":1}]}},{"name":"FoodCourt","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"-0.2838651282377854","max":"1.9566433495195388","histogram":[{"bin_start":-0.2838651282377854,"bin_end":-0.059814280462053004,"count":3},{"bin_start":-0.059814280462053004,"bin_end":0.16423656731367942,"count":0},{"bin_start":0.16423656731367942,"bin_end":0.3882874150894119,"count":0},{"bin_start":0.3882874150894119,"bin_end":0.6123382628651443,"count":1},{"bin_start":0.6123382628651443,"bin_end":0.8363891106408766,"count":0},{"bin_start":0.8363891106408766,"bin_end":1.0604399584166093,"count":0},{"bin_start":1.0604399584166093,"bin_end":1.2844908061923417,"count":0},{"bin_start":1.2844908061923417,"bin_end":1.508541653968074,"count":0},{"bin_start":1.508541653968074,"bin_end":1.7325925017438064,"count":0},{"bin_start":1.7325925017438064,"bin_end":1.9566433495195388,"count":1}]}},{"name":"ShoppingMall","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":"-0.2873829429551493","max":"0.3332397845143109","histogram":[{"bin_start":-0.2873829429551493,"bin_end":-0.2253206702082033,"count":3},{"bin_start":-0.2253206702082033,"bin_end":-0.16325839746125728,"count":0},{"bin_start":-0.16325839746125728,"bin_end":-0.10119612471431128,"count":0},{"bin_start":-0.10119612471431128,"bin_end":-0.03913385196736524,"count":0},{"bin_start":-0.03913385196736524,"bin_end":0.022928420779580794,"count":1},{"bin_start":0.022928420779580794,"bin_end":0.08499069352652677,"count":0},{"bin_start":0.08499069352652677,"bin_end":0.1470529662734728,"count":0},{"bin_start":0.1470529662734728,"bin_end":0.20911523902041884,"count":0},{"bin_start":0.20911523902041884,"bin_end":0.2711775117673648,"count":0},{"bin_start":0.2711775117673648,"bin_end":0.3332397845143109,"count":1}]}},{"name":"Spa","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"-0.2738262777680785","max":"5.692511954386446","histogram":[{"bin_start":-0.2738262777680785,"bin_end":0.32280754544737394,"count":3},{"bin_start":0.32280754544737394,"bin_end":0.9194413686628264,"count":0},{"bin_start":0.9194413686628264,"bin_end":1.5160751918782789,"count":0},{"bin_start":1.5160751918782789,"bin_end":2.1127090150937313,"count":0},{"bin_start":2.1127090150937313,"bin_end":2.7093428383091838,"count":1},{"bin_start":2.7093428383091838,"bin_end":3.305976661524636,"count":0},{"bin_start":3.305976661524636,"bin_end":3.902610484740089,"count":0},{"bin_start":3.902610484740089,"bin_end":4.499244307955541,"count":0},{"bin_start":4.499244307955541,"bin_end":5.095878131170993,"count":0},{"bin_start":5.095878131170993,"bin_end":5.692511954386446,"count":1}]}},{"name":"VRDeck","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"-0.2658309074152016","max":"-0.0956509707084443","histogram":[{"bin_start":-0.2658309074152016,"bin_end":-0.24881291374452588,"count":2},{"bin_start":-0.24881291374452588,"bin_end":-0.23179492007385014,"count":0},{"bin_start":-0.23179492007385014,"bin_end":-0.21477692640317442,"count":2},{"bin_start":-0.21477692640317442,"bin_end":-0.19775893273249867,"count":0},{"bin_start":-0.19775893273249867,"bin_end":-0.18074093906182295,"count":0},{"bin_start":-0.18074093906182295,"bin_end":-0.16372294539114723,"count":0},{"bin_start":-0.16372294539114723,"bin_end":-0.1467049517204715,"count":0},{"bin_start":-0.1467049517204715,"bin_end":-0.12968695804979577,"count":0},{"bin_start":-0.12968695804979577,"bin_end":-0.11266896437912005,"count":0},{"bin_start":-0.11266896437912005,"bin_end":-0.0956509707084443,"count":1}]}},{"name":"Expenditure","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"-0.5183569229651437","max":"3.1745957912176115","histogram":[{"bin_start":-0.5183569229651437,"bin_end":-0.14906165154686818,"count":2},{"bin_start":-0.14906165154686818,"bin_end":0.22023361987140733,"count":1},{"bin_start":0.22023361987140733,"bin_end":0.5895288912896828,"count":0},{"bin_start":0.5895288912896828,"bin_end":0.9588241627079583,"count":0},{"bin_start":0.9588241627079583,"bin_end":1.328119434126234,"count":1},{"bin_start":1.328119434126234,"bin_end":1.6974147055445092,"count":0},{"bin_start":1.6974147055445092,"bin_end":2.066709976962785,"count":0},{"bin_start":2.066709976962785,"bin_end":2.4360052483810604,"count":0},{"bin_start":2.4360052483810604,"bin_end":2.805300519799336,"count":0},{"bin_start":2.805300519799336,"bin_end":3.1745957912176115,"count":1}]}},{"name":"NoSpending","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":1}]}},{"name":"Group","dtype":"int64","stats":{"unique_count":4,"nan_count":0,"min":"1","max":"4","histogram":[{"bin_start":1,"bin_end":1.3,"count":1},{"bin_start":1.3,"bin_end":1.6,"count":0},{"bin_start":1.6,"bin_end":1.9,"count":0},{"bin_start":1.9,"bin_end":2.2,"count":1},{"bin_start":2.2,"bin_end":2.5,"count":0},{"bin_start":2.5,"bin_end":2.8,"count":0},{"bin_start":2.8,"bin_end":3.1,"count":2},{"bin_start":3.1,"bin_end":3.4,"count":0},{"bin_start":3.4,"bin_end":3.6999999999999997,"count":0},{"bin_start":3.6999999999999997,"bin_end":4,"count":1}]}},{"name":"GroupSize","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"1","max":"2","histogram":[{"bin_start":1,"bin_end":1.1,"count":3},{"bin_start":1.1,"bin_end":1.2,"count":0},{"bin_start":1.2,"bin_end":1.3,"count":0},{"bin_start":1.3,"bin_end":1.4,"count":0},{"bin_start":1.4,"bin_end":1.5,"count":0},{"bin_start":1.5,"bin_end":1.6,"count":0},{"bin_start":1.6,"bin_end":1.7000000000000002,"count":0},{"bin_start":1.7000000000000002,"bin_end":1.8,"count":0},{"bin_start":1.8,"bin_end":1.9,"count":0},{"bin_start":1.9,"bin_end":2,"count":2}]}},{"name":"Solo","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":2},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":3}]}},{"name":"CabinRegion_1","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"1","max":"1","histogram":[{"bin_start":0.5,"bin_end":0.6,"count":0},{"bin_start":0.6,"bin_end":0.7,"count":0},{"bin_start":0.7,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":0},{"bin_start":1,"bin_end":1.1,"count":5},{"bin_start":1.1,"bin_end":1.2000000000000002,"count":0},{"bin_start":1.2000000000000002,"bin_end":1.3,"count":0},{"bin_start":1.3,"bin_end":1.4,"count":0},{"bin_start":1.4,"bin_end":1.5,"count":0}]}},{"name":"CabinRegion_2","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinRegion_3","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinRegion_4","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinRegion_5","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinRegion_6","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinRegion_7","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"FamilySize","dtype":"int64","stats":{"unique_count":3,"nan_count":0,"min":"4","max":"9","histogram":[{"bin_start":4,"bin_end":4.5,"count":2},{"bin_start":4.5,"bin_end":5,"count":0},{"bin_start":5,"bin_end":5.5,"count":0},{"bin_start":5.5,"bin_end":6,"count":0},{"bin_start":6,"bin_end":6.5,"count":0},{"bin_start":6.5,"bin_end":7,"count":0},{"bin_start":7,"bin_end":7.5,"count":2},{"bin_start":7.5,"bin_end":8,"count":0},{"bin_start":8,"bin_end":8.5,"count":0},{"bin_start":8.5,"bin_end":9,"count":1}]}},{"name":"HomePlanet_Earth","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":3},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":2}]}},{"name":"HomePlanet_Europa","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":2},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":3}]}},{"name":"HomePlanet_Mars","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"Destination_55 Cancri e","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"Destination_PSO J318.5-22","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"Destination_TRAPPIST-1e","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"1","max":"1","histogram":[{"bin_start":0.5,"bin_end":0.6,"count":0},{"bin_start":0.6,"bin_end":0.7,"count":0},{"bin_start":0.7,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":0},{"bin_start":1,"bin_end":1.1,"count":5},{"bin_start":1.1,"bin_end":1.2000000000000002,"count":0},{"bin_start":1.2000000000000002,"bin_end":1.3,"count":0},{"bin_start":1.3,"bin_end":1.4,"count":0},{"bin_start":1.4,"bin_end":1.5,"count":0}]}},{"name":"CabinSide_P","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":1}]}},{"name":"CabinSide_S","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":4}]}},{"name":"CabinSide_Z","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinDeck_A","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":3},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":2}]}},{"name":"CabinDeck_B","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":1}]}},{"name":"CabinDeck_C","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinDeck_D","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinDeck_E","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinDeck_F","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":3},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":2}]}},{"name":"CabinDeck_G","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinDeck_T","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"AgeEncoded","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":"1.0","max":"4.0","histogram":[{"bin_start":1,"bin_end":1.3,"count":1},{"bin_start":1.3,"bin_end":1.6,"count":0},{"bin_start":1.6,"bin_end":1.9,"count":0},{"bin_start":1.9,"bin_end":2.2,"count":2},{"bin_start":2.2,"bin_end":2.5,"count":0},{"bin_start":2.5,"bin_end":2.8,"count":0},{"bin_start":2.8,"bin_end":3.1,"count":1},{"bin_start":3.1,"bin_end":3.4,"count":0},{"bin_start":3.4,"bin_end":3.6999999999999997,"count":0},{"bin_start":3.6999999999999997,"bin_end":4,"count":1}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"PassengerId":"0001_01","CryoSleep":0,"VIP":0,"RoomService":-0.3375298928969419,"FoodCourt":-0.2838651282377854,"ShoppingMall":-0.2873829429551493,"Spa":-0.2738262777680785,"VRDeck":-0.2658309074152016,"Expenditure":-0.5183569229651437,"NoSpending":1,"Group":1,"GroupSize":1,"Solo":1,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":4,"HomePlanet_Earth":0,"HomePlanet_Europa":1,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":1,"CabinSide_S":0,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":1,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":3,"_deepnote_index_column":0},{"PassengerId":"0002_01","CryoSleep":0,"VIP":0,"RoomService":-0.1724547480018475,"FoodCourt":-0.2782262646192686,"ShoppingMall":-0.2455620044464256,"Spa":0.2139651875264611,"VRDeck":-0.2270334088913813,"Expenditure":-0.2565815981420186,"NoSpending":0,"Group":2,"GroupSize":1,"Solo":1,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":4,"HomePlanet_Earth":1,"HomePlanet_Europa":0,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":0,"CabinSide_S":1,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":1,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":2,"_deepnote_index_column":1},{"PassengerId":"0003_01","CryoSleep":0,"VIP":1,"RoomService":-0.2724085054612624,"FoodCourt":1.9566433495195388,"ShoppingMall":-0.2873829429551493,"Spa":5.692511954386446,"VRDeck":-0.2226246022409472,"Expenditure":3.1745957912176115,"NoSpending":0,"Group":3,"GroupSize":2,"Solo":0,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":7,"HomePlanet_Earth":0,"HomePlanet_Europa":1,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":0,"CabinSide_S":1,"CabinSide_Z":0,"CabinDeck_A":1,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":4,"_deepnote_index_column":2},{"PassengerId":"0003_02","CryoSleep":0,"VIP":0,"RoomService":-0.3375298928969419,"FoodCourt":0.5199862076018809,"ShoppingMall":0.3332397845143109,"Spa":2.6840203305479915,"VRDeck":-0.0956509707084443,"Expenditure":1.3226065026931382,"NoSpending":0,"Group":3,"GroupSize":2,"Solo":0,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":7,"HomePlanet_Earth":0,"HomePlanet_Europa":1,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":0,"CabinSide_S":1,"CabinSide_Z":0,"CabinDeck_A":1,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":2,"_deepnote_index_column":3},{"PassengerId":"0004_01","CryoSleep":0,"VIP":0,"RoomService":0.1213487208940084,"FoodCourt":-0.2400073000937662,"ShoppingMall":-0.0347844743624579,"Spa":0.2281813322344987,"VRDeck":-0.264067384755028,"Expenditure":-0.1303176846743428,"NoSpending":0,"Group":4,"GroupSize":1,"Solo":1,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":9,"HomePlanet_Earth":1,"HomePlanet_Europa":0,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":0,"CabinSide_S":1,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":1,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":1,"_deepnote_index_column":4}]},"text/plain":"  PassengerId  CryoSleep  VIP  RoomService  FoodCourt  ShoppingMall       Spa  \\\n0     0001_01          0    0    -0.337530  -0.283865     -0.287383 -0.273826   \n1     0002_01          0    0    -0.172455  -0.278226     -0.245562  0.213965   \n2     0003_01          0    1    -0.272409   1.956643     -0.287383  5.692512   \n3     0003_02          0    0    -0.337530   0.519986      0.333240  2.684020   \n4     0004_01          0    0     0.121349  -0.240007     -0.034784  0.228181   \n\n     VRDeck  Expenditure  NoSpending  ...  CabinSide_Z  CabinDeck_A  \\\n0 -0.265831    -0.518357           1  ...            0            0   \n1 -0.227033    -0.256582           0  ...            0            0   \n2 -0.222625     3.174596           0  ...            0            1   \n3 -0.095651     1.322607           0  ...            0            1   \n4 -0.264067    -0.130318           0  ...            0            0   \n\n   CabinDeck_B  CabinDeck_C  CabinDeck_D  CabinDeck_E  CabinDeck_F  \\\n0            1            0            0            0            0   \n1            0            0            0            0            1   \n2            0            0            0            0            0   \n3            0            0            0            0            0   \n4            0            0            0            0            1   \n\n   CabinDeck_G  CabinDeck_T  AgeEncoded  \n0            0            0         3.0  \n1            0            0         2.0  \n2            0            0         4.0  \n3            0            0         2.0  \n4            0            0         1.0  \n\n[5 rows x 39 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>CryoSleep</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Expenditure</th>\n      <th>NoSpending</th>\n      <th>...</th>\n      <th>CabinSide_Z</th>\n      <th>CabinDeck_A</th>\n      <th>CabinDeck_B</th>\n      <th>CabinDeck_C</th>\n      <th>CabinDeck_D</th>\n      <th>CabinDeck_E</th>\n      <th>CabinDeck_F</th>\n      <th>CabinDeck_G</th>\n      <th>CabinDeck_T</th>\n      <th>AgeEncoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001_01</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.337530</td>\n      <td>-0.283865</td>\n      <td>-0.287383</td>\n      <td>-0.273826</td>\n      <td>-0.265831</td>\n      <td>-0.518357</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002_01</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.172455</td>\n      <td>-0.278226</td>\n      <td>-0.245562</td>\n      <td>0.213965</td>\n      <td>-0.227033</td>\n      <td>-0.256582</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0003_01</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-0.272409</td>\n      <td>1.956643</td>\n      <td>-0.287383</td>\n      <td>5.692512</td>\n      <td>-0.222625</td>\n      <td>3.174596</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0003_02</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.337530</td>\n      <td>0.519986</td>\n      <td>0.333240</td>\n      <td>2.684020</td>\n      <td>-0.095651</td>\n      <td>1.322607</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0004_01</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.121349</td>\n      <td>-0.240007</td>\n      <td>-0.034784</td>\n      <td>0.228181</td>\n      <td>-0.264067</td>\n      <td>-0.130318</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/d8d4b96d-b1e5-4e0d-b7a2-3c7d05f7c433","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193623473,"execution_millis":299,"deepnote_to_be_reexecuted":false,"cell_id":"6139d2a8b1494595a916f46b3642e63c","deepnote_cell_type":"code"},"source":"from sklearn.model_selection import train_test_split\n\n# Memisahkan data menjadi train dan validation set\nX_train, X_val, y_train, y_val = train_test_split(X_df, y_df, test_size=0.2, random_state=42)\n# Mengubah target menjadi 1D array\ny_train = y_train['Transported'].values\ny_test = y_val['Transported'].values","block_group":"f3e98e79ef544fb98587f50a6297debd","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"56238f44ef4e415f9f8ce979c3309d20","deepnote_cell_type":"text-cell-h1"},"source":"# Model Training","block_group":"e01f12f006324577a8685ffcb2e53c45"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193623474,"execution_millis":298,"deepnote_to_be_reexecuted":false,"cell_id":"c1ae958a487f4a40be25a7fc85690852","deepnote_cell_type":"code"},"source":"\n# Membuat pipeline\n\npipeline = Pipeline([\n    ('scaler', MinMaxScaler()),\n    ('classifier', LGBMClassifier(random_state=42))\n])\n\n\n\nparam_grid = {\n    'classifier__n_estimators': [500],\n    'classifier__max_depth': [10],\n    'classifier__learning_rate': [0.01],\n    'classifier__subsample': [0.8],\n    'classifier__colsample_bytree': [1]\n}\n\n# Menggunakan StratifiedKFold untuk handling imbalanced data\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","block_group":"ffa1a5a6dc0742f6a823ee9eafca1c28","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193623508,"execution_millis":6871,"deepnote_to_be_reexecuted":false,"cell_id":"62e7b779b6e74147a1223ca0f7e61a95","deepnote_cell_type":"code"},"source":"# Membuat GridSearchCV dengan cv yang lebih robust\ngrid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='accuracy', verbose=1)\ngrid_search.fit(X_train, y_train)\n\n# Menampilkan parameter terbaik dan skor\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))","block_group":"f25cc19a7dc748ebb5ccf17f344e75e3","execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 10 folds for each of 1 candidates, totalling 10 fits\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3108\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000606 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6258, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503356 -> initscore=0.013423\n[LightGBM] [Info] Start training from score 0.013423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3108\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000704 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6258, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503356 -> initscore=0.013423\n[LightGBM] [Info] Start training from score 0.013423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3108\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6258, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503356 -> initscore=0.013423\n[LightGBM] [Info] Start training from score 0.013423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3108\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000664 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6258, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503356 -> initscore=0.013423\n[LightGBM] [Info] Start training from score 0.013423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3109\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6259, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503275 -> initscore=0.013101\n[LightGBM] [Info] Start training from score 0.013101\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3109\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6259, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503275 -> initscore=0.013101\n[LightGBM] [Info] Start training from score 0.013101\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3109\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6259, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503275 -> initscore=0.013101\n[LightGBM] [Info] Start training from score 0.013101\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3109\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6259, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503275 -> initscore=0.013101\n[LightGBM] [Info] Start training from score 0.013101\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3109\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6259, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503275 -> initscore=0.013101\n[LightGBM] [Info] Start training from score 0.013101\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3109\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6259, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503275 -> initscore=0.013101\n[LightGBM] [Info] Start training from score 0.013101\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000841 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n[LightGBM] [Info] Start training from score 0.013230\nBest parameters: {'classifier__colsample_bytree': 1, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 10, 'classifier__n_estimators': 500, 'classifier__subsample': 0.8}\nBest cross-validation score: 0.81\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/d823c2fb-66fd-4186-96b5-1635ed9b8b9a","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193630388,"execution_millis":8020,"deepnote_to_be_reexecuted":false,"cell_id":"6bc42597f15d475da99bce8283a393b8","deepnote_cell_type":"code"},"source":"# Menggunakan estimator terbaik untuk prediksi pada data test\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_val)\n\n# Evaluasi model pada data test\nprint(\"Accuracy on test set:\", accuracy_score(y_val, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_val, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n\n# Fit the model on all training data\ngrid_search.fit(X_df, y_df)","block_group":"1f877861536747488f387d65084fb3b1","execution_count":null,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\nAccuracy on test set: 0.7993099482461185\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.81      0.78      0.79       861\n           1       0.79      0.82      0.80       878\n\n    accuracy                           0.80      1739\n   macro avg       0.80      0.80      0.80      1739\nweighted avg       0.80      0.80      0.80      1739\n\nConfusion Matrix:\n [[671 190]\n [159 719]]\nFitting 10 folds for each of 1 candidates, totalling 10 fits\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000862 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000846 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000845 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n[LightGBM] [Info] Start training from score 0.014826\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000833 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n[LightGBM] [Info] Start training from score 0.014826\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000660 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000850 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000838 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000843 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000846 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000941 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n[LightGBM] [Info] Start training from score 0.014495\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n             estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n                                       ('classifier',\n                                        LGBMClassifier(random_state=42))]),\n             param_grid={'classifier__colsample_bytree': [1],\n                         'classifier__learning_rate': [0.01],\n                         'classifier__max_depth': [10],\n                         'classifier__n_estimators': [500],\n                         'classifier__subsample': [0.8]},\n             scoring='accuracy', verbose=1)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n                                       (&#x27;classifier&#x27;,\n                                        LGBMClassifier(random_state=42))]),\n             param_grid={&#x27;classifier__colsample_bytree&#x27;: [1],\n                         &#x27;classifier__learning_rate&#x27;: [0.01],\n                         &#x27;classifier__max_depth&#x27;: [10],\n                         &#x27;classifier__n_estimators&#x27;: [500],\n                         &#x27;classifier__subsample&#x27;: [0.8]},\n             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n                                       (&#x27;classifier&#x27;,\n                                        LGBMClassifier(random_state=42))]),\n             param_grid={&#x27;classifier__colsample_bytree&#x27;: [1],\n                         &#x27;classifier__learning_rate&#x27;: [0.01],\n                         &#x27;classifier__max_depth&#x27;: [10],\n                         &#x27;classifier__n_estimators&#x27;: [500],\n                         &#x27;classifier__subsample&#x27;: [0.8]},\n             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n                (&#x27;classifier&#x27;, LGBMClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/10c67149-8b05-406a-99a6-89260833297b","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"263245765c4e4c9d91f2910db50857aa","deepnote_cell_type":"text-cell-h1"},"source":"# Submission Prediction","block_group":"4c856cb090fc4ca8847589c39997e4a2"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193638417,"execution_millis":8164,"deepnote_to_be_reexecuted":false,"cell_id":"e22e41abdfad4bb7aa5055cc76f05f4f","deepnote_cell_type":"code"},"source":"# For training, we use ALL data from spaceship_train_X_v2.csv and spaceship_train_y.csv\ngrid_search.fit(X_df, y_df['Transported'].values)\n# Prediksi data submission\ny_prediction = grid_search.predict(X_submission)\nprint(y_prediction)\n","block_group":"51e9e9b1a74b47e3beec7c41ad94151c","execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 10 folds for each of 1 candidates, totalling 10 fits\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000703 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000879 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000870 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000897 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n[LightGBM] [Info] Start training from score 0.014826\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000875 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n[LightGBM] [Info] Start training from score 0.014826\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000665 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000924 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001078 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000918 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000834 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001095 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n[LightGBM] [Info] Start training from score 0.014495\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[1 0 1 ... 1 1 1]\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/29ec13f3-17e5-479c-b70b-6d5e141b5600","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193646591,"execution_millis":568,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":100,"pageIndex":0},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"cell_id":"37811a64d13441b1ab8246577c7e2607","deepnote_cell_type":"code"},"source":"submission_dict = {'PassengerId':X_submission['PassengerId'], 'Transported':y_prediction.astype('bool')}\nsubmission_dict = pd.DataFrame(submission_dict)\nsubmission_dict","block_group":"dd269131f3a14a0d86bd4f70d52f78ba","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":2,"row_count":4277,"columns":[{"name":"PassengerId","dtype":"object","stats":{"unique_count":4277,"nan_count":0,"categories":[{"name":"0013_01","count":1},{"name":"0018_01","count":1},{"name":"4275 others","count":4275}]}},{"name":"Transported","dtype":"bool","stats":{"unique_count":2,"nan_count":0,"categories":[{"name":"False","count":2179},{"name":"True","count":2098}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"PassengerId":"0013_01","Transported":"True","_deepnote_index_column":0},{"PassengerId":"0018_01","Transported":"False","_deepnote_index_column":1},{"PassengerId":"0019_01","Transported":"True","_deepnote_index_column":2},{"PassengerId":"0021_01","Transported":"True","_deepnote_index_column":3},{"PassengerId":"0023_01","Transported":"True","_deepnote_index_column":4},{"PassengerId":"0027_01","Transported":"True","_deepnote_index_column":5},{"PassengerId":"0029_01","Transported":"True","_deepnote_index_column":6},{"PassengerId":"0032_01","Transported":"True","_deepnote_index_column":7},{"PassengerId":"0032_02","Transported":"True","_deepnote_index_column":8},{"PassengerId":"0033_01","Transported":"True","_deepnote_index_column":9},{"PassengerId":"0037_01","Transported":"False","_deepnote_index_column":10},{"PassengerId":"0040_01","Transported":"False","_deepnote_index_column":11},{"PassengerId":"0040_02","Transported":"False","_deepnote_index_column":12},{"PassengerId":"0042_01","Transported":"False","_deepnote_index_column":13},{"PassengerId":"0046_01","Transported":"False","_deepnote_index_column":14},{"PassengerId":"0046_02","Transported":"False","_deepnote_index_column":15},{"PassengerId":"0046_03","Transported":"False","_deepnote_index_column":16},{"PassengerId":"0047_01","Transported":"True","_deepnote_index_column":17},{"PassengerId":"0047_02","Transported":"True","_deepnote_index_column":18},{"PassengerId":"0047_03","Transported":"False","_deepnote_index_column":19},{"PassengerId":"0048_01","Transported":"True","_deepnote_index_column":20},{"PassengerId":"0049_01","Transported":"False","_deepnote_index_column":21},{"PassengerId":"0054_01","Transported":"True","_deepnote_index_column":22},{"PassengerId":"0054_02","Transported":"True","_deepnote_index_column":23},{"PassengerId":"0054_03","Transported":"False","_deepnote_index_column":24},{"PassengerId":"0055_01","Transported":"False","_deepnote_index_column":25},{"PassengerId":"0057_01","Transported":"True","_deepnote_index_column":26},{"PassengerId":"0059_01","Transported":"True","_deepnote_index_column":27},{"PassengerId":"0060_01","Transported":"False","_deepnote_index_column":28},{"PassengerId":"0063_01","Transported":"True","_deepnote_index_column":29},{"PassengerId":"0065_01","Transported":"True","_deepnote_index_column":30},{"PassengerId":"0075_01","Transported":"False","_deepnote_index_column":31},{"PassengerId":"0079_01","Transported":"True","_deepnote_index_column":32},{"PassengerId":"0080_01","Transported":"False","_deepnote_index_column":33},{"PassengerId":"0083_01","Transported":"False","_deepnote_index_column":34},{"PassengerId":"0087_01","Transported":"False","_deepnote_index_column":35},{"PassengerId":"0089_01","Transported":"True","_deepnote_index_column":36},{"PassengerId":"0093_01","Transported":"True","_deepnote_index_column":37},{"PassengerId":"0094_01","Transported":"True","_deepnote_index_column":38},{"PassengerId":"0094_02","Transported":"False","_deepnote_index_column":39},{"PassengerId":"0095_01","Transported":"True","_deepnote_index_column":40},{"PassengerId":"0096_01","Transported":"False","_deepnote_index_column":41},{"PassengerId":"0100_01","Transported":"True","_deepnote_index_column":42},{"PassengerId":"0100_02","Transported":"False","_deepnote_index_column":43},{"PassengerId":"0104_01","Transported":"False","_deepnote_index_column":44},{"PassengerId":"0106_01","Transported":"True","_deepnote_index_column":45},{"PassengerId":"0109_01","Transported":"False","_deepnote_index_column":46},{"PassengerId":"0117_01","Transported":"False","_deepnote_index_column":47},{"PassengerId":"0118_01","Transported":"False","_deepnote_index_column":48},{"PassengerId":"0121_01","Transported":"False","_deepnote_index_column":49},{"PassengerId":"0124_01","Transported":"True","_deepnote_index_column":50},{"PassengerId":"0125_01","Transported":"True","_deepnote_index_column":51},{"PassengerId":"0125_02","Transported":"False","_deepnote_index_column":52},{"PassengerId":"0130_01","Transported":"True","_deepnote_index_column":53},{"PassengerId":"0131_01","Transported":"False","_deepnote_index_column":54},{"PassengerId":"0132_01","Transported":"True","_deepnote_index_column":55},{"PassengerId":"0135_01","Transported":"False","_deepnote_index_column":56},{"PassengerId":"0137_01","Transported":"True","_deepnote_index_column":57},{"PassengerId":"0142_01","Transported":"True","_deepnote_index_column":58},{"PassengerId":"0142_02","Transported":"False","_deepnote_index_column":59},{"PassengerId":"0142_03","Transported":"True","_deepnote_index_column":60},{"PassengerId":"0143_01","Transported":"True","_deepnote_index_column":61},{"PassengerId":"0145_01","Transported":"False","_deepnote_index_column":62},{"PassengerId":"0150_01","Transported":"True","_deepnote_index_column":63},{"PassengerId":"0150_02","Transported":"True","_deepnote_index_column":64},{"PassengerId":"0153_01","Transported":"False","_deepnote_index_column":65},{"PassengerId":"0154_01","Transported":"True","_deepnote_index_column":66},{"PassengerId":"0155_01","Transported":"False","_deepnote_index_column":67},{"PassengerId":"0156_01","Transported":"True","_deepnote_index_column":68},{"PassengerId":"0157_01","Transported":"False","_deepnote_index_column":69},{"PassengerId":"0158_01","Transported":"False","_deepnote_index_column":70},{"PassengerId":"0158_02","Transported":"True","_deepnote_index_column":71},{"PassengerId":"0159_01","Transported":"False","_deepnote_index_column":72},{"PassengerId":"0161_01","Transported":"False","_deepnote_index_column":73},{"PassengerId":"0162_01","Transported":"True","_deepnote_index_column":74},{"PassengerId":"0166_01","Transported":"True","_deepnote_index_column":75},{"PassengerId":"0168_01","Transported":"True","_deepnote_index_column":76},{"PassengerId":"0175_01","Transported":"False","_deepnote_index_column":77},{"PassengerId":"0175_02","Transported":"True","_deepnote_index_column":78},{"PassengerId":"0175_03","Transported":"False","_deepnote_index_column":79},{"PassengerId":"0175_04","Transported":"False","_deepnote_index_column":80},{"PassengerId":"0175_05","Transported":"False","_deepnote_index_column":81},{"PassengerId":"0176_01","Transported":"False","_deepnote_index_column":82},{"PassengerId":"0180_01","Transported":"False","_deepnote_index_column":83},{"PassengerId":"0184_01","Transported":"True","_deepnote_index_column":84},{"PassengerId":"0185_01","Transported":"True","_deepnote_index_column":85},{"PassengerId":"0187_01","Transported":"True","_deepnote_index_column":86},{"PassengerId":"0191_01","Transported":"False","_deepnote_index_column":87},{"PassengerId":"0194_01","Transported":"True","_deepnote_index_column":88},{"PassengerId":"0194_02","Transported":"True","_deepnote_index_column":89},{"PassengerId":"0194_03","Transported":"False","_deepnote_index_column":90},{"PassengerId":"0204_01","Transported":"False","_deepnote_index_column":91},{"PassengerId":"0208_01","Transported":"False","_deepnote_index_column":92},{"PassengerId":"0209_01","Transported":"False","_deepnote_index_column":93},{"PassengerId":"0214_01","Transported":"False","_deepnote_index_column":94},{"PassengerId":"0214_02","Transported":"False","_deepnote_index_column":95},{"PassengerId":"0215_01","Transported":"True","_deepnote_index_column":96},{"PassengerId":"0218_01","Transported":"False","_deepnote_index_column":97},{"PassengerId":"0226_01","Transported":"True","_deepnote_index_column":98},{"PassengerId":"0227_01","Transported":"True","_deepnote_index_column":99}]},"text/plain":"     PassengerId  Transported\n0        0013_01         True\n1        0018_01        False\n2        0019_01         True\n3        0021_01         True\n4        0023_01         True\n...          ...          ...\n4272     9266_02         True\n4273     9269_01        False\n4274     9271_01         True\n4275     9273_01         True\n4276     9277_01         True\n\n[4277 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Transported</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0013_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0018_01</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0019_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0021_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0023_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4272</th>\n      <td>9266_02</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4273</th>\n      <td>9269_01</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4274</th>\n      <td>9271_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4275</th>\n      <td>9273_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4276</th>\n      <td>9277_01</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>4277 rows × 2 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/cc9259f7-0516-445f-88aa-94b30a53430f","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"be2abaeff1fe4a8796eeba316514f1ae","deepnote_cell_type":"text-cell-h2"},"source":"## Export CSV","block_group":"11179e1880944debabb23367b2d4f7f0"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715194401883,"execution_millis":145,"deepnote_to_be_reexecuted":false,"cell_id":"aa933668edd245299ec2d88c1f203c6b","deepnote_cell_type":"code"},"source":"submission_dict.to_csv('spaceship_lightgbm6.csv', index=False)","block_group":"af3684a41e194ff4ba4e0fbc07d01dd3","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=2a79941c-6614-47fe-9427-0e9f23998893' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2024-05-19T12:45:10.797Z"},"deepnote_notebook_id":"0601033307f545e1a92538eed0a9d062","deepnote_execution_queue":[]}}
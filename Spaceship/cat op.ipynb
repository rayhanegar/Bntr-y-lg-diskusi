{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"e1fb45ed610645e78ff8ad9e8936ce82","deepnote_cell_type":"text-cell-h1"},"source":"# Spaceship Lightgbm Submission","block_group":"082f42d739ae4c33b25722d4d688de17"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715899763892,"execution_millis":10784,"deepnote_to_be_reexecuted":false,"cell_id":"244c425f5c7b4a5eb75784590eebdb69","deepnote_cell_type":"code"},"source":"!pip install lightgbm==4.3.0","block_group":"ed00792b3cca4a8e878c8e325bb73c4b","execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: lightgbm==4.3.0 in /root/venv/lib/python3.9/site-packages (4.3.0)\nRequirement already satisfied: numpy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from lightgbm==4.3.0) (1.23.4)\nRequirement already satisfied: scipy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from lightgbm==4.3.0) (1.9.3)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/11d39d18-e63a-473f-9715-b8daf21f0e3e","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193622612,"execution_millis":455,"deepnote_to_be_reexecuted":false,"cell_id":"242674e8b3fe4763b44be6283b4268e0","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler","block_group":"6d67ae98cbb84c27b03fe6f9075b0099","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715900418296,"execution_millis":418273,"deepnote_to_be_reexecuted":false,"cell_id":"e6fd02cca1fa461080f362b3499e5d69","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport optuna\n\n# Load datasets\nX_df = pd.read_csv('spaceship_train_X_v2.csv')\ny_df = pd.read_csv('spaceship_train_y.csv')\nX_submission = pd.read_csv('spaceship_test_X_v2.csv')\n\n# Drop unnecessary columns\ny_df.drop('Unnamed: 0', axis=1, inplace=True)\nX_df.drop('PassengerId', axis=1, inplace=True)\nX_submission_ids = X_submission['PassengerId']\nX_submission.drop('PassengerId', axis=1, inplace=True)\n\n# Split data\nX_train, X_val, y_train, y_val = train_test_split(X_df, y_df['Transported'], test_size=0.2, random_state=42)\n\n# Standardize data\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\nX_submission_scaled = scaler.transform(X_submission)\n\n# Define objective function for Optuna\ndef objective(trial):\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0)\n    }\n\n    lgbm = LGBMClassifier(**param, random_state=42)\n    lgbm.fit(X_train_scaled, y_train)\n    y_pred = lgbm.predict(X_val_scaled)\n    accuracy = accuracy_score(y_val, y_pred)\n    return accuracy\n\n# Optimize hyperparameters with Optuna\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=200)\n\n# Print best hyperparameters\nprint('Best hyperparameters:', study.best_params)\n\n# Train final model with best hyperparameters\nbest_params = study.best_params\nlgbm_optimized = LGBMClassifier(**best_params, random_state=42)\nlgbm_optimized.fit(X_train_scaled, y_train)\n\n# Evaluate the model\ny_pred_optimized = lgbm_optimized.predict(X_val_scaled)\nprint(\"Accuracy on validation set:\", accuracy_score(y_val, y_pred_optimized))\nprint(\"Classification Report:\\n\", classification_report(y_val, y_pred_optimized))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred_optimized))\n\n# Fit the model on all training data\nX_df_scaled = scaler.fit_transform(X_df)\nlgbm_optimized.fit(X_df_scaled, y_df['Transported'])\n\n# Predict on submission data\ny_submission_pred = lgbm_optimized.predict(X_submission_scaled)\n\n# Create submission file\nsubmission_dict = {'PassengerId': X_submission_ids, 'Transported': y_submission_pred.astype('bool')}\nsubmission_df = pd.DataFrame(submission_dict)\nsubmission_df.to_csv('spaceship_lgbm_optimized.csv', index=False)\n","block_group":"68048287a1f0465aa79b02a3e81aadcf","execution_count":null,"outputs":[{"name":"stderr","text":"[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nAccuracy on validation set: 0.8056354226566993\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.81      0.80      0.80       861\n           1       0.81      0.81      0.81       878\n\n    accuracy                           0.81      1739\n   macro avg       0.81      0.81      0.81      1739\nweighted avg       0.81      0.81      0.81      1739\n\nConfusion Matrix:\n [[690 171]\n [167 711]]\n[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001222 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1871\n[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 37\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n[LightGBM] [Info] Start training from score 0.014495\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/777bffe8-6bb6-4742-a5c8-7f9428ae06dd","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715960401672,"execution_millis":5014,"deepnote_to_be_reexecuted":false,"cell_id":"ec69062b28ba4401aeb43ea0dfa9c8ed","deepnote_cell_type":"code"},"source":"!pip install catboost==1.2.5","block_group":"6eaa32b0640b402195b0bd83c682e959","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting catboost==1.2.5\n  Downloading catboost-1.2.5-cp39-cp39-manylinux2014_x86_64.whl (98.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting graphviz\n  Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas>=0.24 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from catboost==1.2.5) (2.1.4)\nRequirement already satisfied: scipy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from catboost==1.2.5) (1.9.3)\nRequirement already satisfied: plotly in /shared-libs/python3.9/py/lib/python3.9/site-packages (from catboost==1.2.5) (5.10.0)\nRequirement already satisfied: matplotlib in /shared-libs/python3.9/py/lib/python3.9/site-packages (from catboost==1.2.5) (3.6.0)\nRequirement already satisfied: six in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from catboost==1.2.5) (1.16.0)\nRequirement already satisfied: numpy>=1.16.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from catboost==1.2.5) (1.23.4)\nRequirement already satisfied: tzdata>=2022.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pandas>=0.24->catboost==1.2.5) (2022.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from pandas>=0.24->catboost==1.2.5) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pandas>=0.24->catboost==1.2.5) (2022.5)\nRequirement already satisfied: cycler>=0.10 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (1.4.4)\nRequirement already satisfied: contourpy>=1.0.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (1.0.5)\nRequirement already satisfied: pillow>=6.2.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (9.2.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (3.0.9)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (21.3)\nRequirement already satisfied: fonttools>=4.22.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->catboost==1.2.5) (4.37.4)\nRequirement already satisfied: tenacity>=6.2.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from plotly->catboost==1.2.5) (8.1.0)\nInstalling collected packages: graphviz, catboost\nSuccessfully installed catboost-1.2.5 graphviz-0.20.3\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/6751ce2e-c693-4999-922b-1cad369e4b2c","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715960429756,"execution_millis":2897,"deepnote_to_be_reexecuted":false,"cell_id":"9c3d4ab3b3dd4bb38f90bc3a76e76573","deepnote_cell_type":"code"},"source":"!pip install optuna==3.6.1","block_group":"08f65ffc29124b24a08d8ff7b5cd8ce6","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting optuna==3.6.1\n  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from optuna==3.6.1) (1.23.4)\nCollecting PyYAML\n  Downloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.9/738.9 kB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting colorlog\n  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\nRequirement already satisfied: tqdm in /shared-libs/python3.9/py/lib/python3.9/site-packages (from optuna==3.6.1) (4.64.1)\nRequirement already satisfied: alembic>=1.5.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from optuna==3.6.1) (1.11.1)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from optuna==3.6.1) (1.4.42)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from optuna==3.6.1) (21.3)\nRequirement already satisfied: Mako in /shared-libs/python3.9/py/lib/python3.9/site-packages (from alembic>=1.5.0->optuna==3.6.1) (1.2.4)\nRequirement already satisfied: typing-extensions>=4 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from alembic>=1.5.0->optuna==3.6.1) (4.4.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from packaging>=20.0->optuna==3.6.1) (3.0.9)\nRequirement already satisfied: greenlet!=0.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from sqlalchemy>=1.3.0->optuna==3.6.1) (1.1.3.post0)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna==3.6.1) (2.0.0)\nInstalling collected packages: PyYAML, colorlog, optuna\nSuccessfully installed PyYAML-6.0.1 colorlog-6.8.2 optuna-3.6.1\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/7d924b49-0e56-4fa4-8177-7b35a76b9ce0","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715964937324,"execution_millis":611422,"deepnote_to_be_reexecuted":false,"cell_id":"6de9222397af417bb6786dd3a8d96bb9","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport optuna\n\n# Load datasets\nX_df = pd.read_csv('spaceship_train_X_v2.csv')\ny_df = pd.read_csv('spaceship_train_y.csv')\nX_submission = pd.read_csv('spaceship_test_X_v2.csv')\n\n# Drop unnecessary columns\ny_df.drop('Unnamed: 0', axis=1, inplace=True)\nX_df.drop('PassengerId', axis=1, inplace=True)\nX_submission_ids = X_submission['PassengerId']\nX_submission.drop('PassengerId', axis=1, inplace=True)\n\n# Split data\nX_train, X_val, y_train, y_val = train_test_split(X_df, y_df['Transported'], test_size=0.2, random_state=42)\n\n# Standardize data\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\nX_submission_scaled = scaler.transform(X_submission)\n\n# Define objective function for Optuna\ndef objective(trial):\n    param = {\n        'iterations': trial.suggest_int('iterations', 100, 1000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'depth': trial.suggest_int('depth', 3, 16),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-5, 100),\n        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n        'random_strength': trial.suggest_float('random_strength', 0.0, 1.0),\n        'border_count': trial.suggest_int('border_count', 1, 255)\n    }\n\n    catboost = CatBoostClassifier(**param, random_state=42, verbose=0)\n    catboost.fit(X_train_scaled, y_train)\n    y_pred = catboost.predict(X_val_scaled)\n    accuracy = accuracy_score(y_val, y_pred)\n    return accuracy\n\n# Optimize hyperparameters with Optuna\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=10)\n\n# Print best hyperparameters\nprint('Best hyperparameters:', study.best_params)\n\n# Train final model with best hyperparameters\nbest_params = study.best_params\ncatboost_optimized = CatBoostClassifier(**best_params, random_state=42, verbose=0)\ncatboost_optimized.fit(X_train_scaled, y_train)\n\n# Evaluate the model\ny_pred_optimized = catboost_optimized.predict(X_val_scaled)\nprint(\"Accuracy on validation set:\", accuracy_score(y_val, y_pred_optimized))\nprint(\"Classification Report:\\n\", classification_report(y_val, y_pred_optimized))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred_optimized))\n\n# Fit the model on all training data\nX_df_scaled = scaler.fit_transform(X_df)\ncatboost_optimized.fit(X_df_scaled, y_df['Transported'])\n\n# Predict on submission data\ny_submission_pred = catboost_optimized.predict(X_submission_scaled)\n\n# Create submission file\nsubmission_dict = {'PassengerId': X_submission_ids, 'Transported': y_submission_pred.astype('bool')}\nsubmission_df = pd.DataFrame(submission_dict)\nsubmission_df.to_csv('spaceship_catboost_optimized.csv', index=False)\n","block_group":"7e1cbf3c7b67437787cf90ec2045c667","execution_count":null,"outputs":[{"name":"stderr","text":"/shared-libs/python3.9/py/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n[I 2024-05-17 16:55:39,000] A new study created in memory with name: no-name-f5985eb2-1c72-4967-8c52-d0495bd659fd\n[I 2024-05-17 16:57:28,554] Trial 0 finished with value: 0.7901092581943646 and parameters: {'iterations': 747, 'learning_rate': 0.19127648890743468, 'depth': 13, 'l2_leaf_reg': 31.53700682896767, 'bagging_temperature': 0.1921633056602322, 'random_strength': 0.9017837325341022, 'border_count': 51}. Best is trial 0 with value: 0.7901092581943646.\n[I 2024-05-17 16:57:33,256] Trial 1 finished with value: 0.7987349051178838 and parameters: {'iterations': 811, 'learning_rate': 0.16120195322541006, 'depth': 4, 'l2_leaf_reg': 64.80933581315008, 'bagging_temperature': 0.5989308264972837, 'random_strength': 0.6045036910138146, 'border_count': 132}. Best is trial 1 with value: 0.7987349051178838.\n[I 2024-05-17 16:59:39,647] Trial 2 finished with value: 0.7855089131684876 and parameters: {'iterations': 512, 'learning_rate': 0.11906134052473882, 'depth': 13, 'l2_leaf_reg': 18.902766923230477, 'bagging_temperature': 0.13482367239115123, 'random_strength': 0.16457574478551862, 'border_count': 174}. Best is trial 1 with value: 0.7987349051178838.\n[I 2024-05-17 17:00:43,661] Trial 3 finished with value: 0.7941345600920069 and parameters: {'iterations': 882, 'learning_rate': 0.02425365760822043, 'depth': 11, 'l2_leaf_reg': 96.93167319022739, 'bagging_temperature': 0.6566660993204576, 'random_strength': 0.12480178795704544, 'border_count': 207}. Best is trial 1 with value: 0.7987349051178838.\n[I 2024-05-17 17:00:51,809] Trial 4 finished with value: 0.7958596894767107 and parameters: {'iterations': 404, 'learning_rate': 0.28449167122848024, 'depth': 9, 'l2_leaf_reg': 78.9673477181054, 'bagging_temperature': 0.44337159687458283, 'random_strength': 0.35518218478220653, 'border_count': 111}. Best is trial 1 with value: 0.7987349051178838.\n[I 2024-05-17 17:02:07,447] Trial 5 finished with value: 0.7918343875790684 and parameters: {'iterations': 585, 'learning_rate': 0.29189653961433065, 'depth': 12, 'l2_leaf_reg': 85.13233900890171, 'bagging_temperature': 0.00779478693007396, 'random_strength': 0.6502651742425317, 'border_count': 190}. Best is trial 1 with value: 0.7987349051178838.\n[I 2024-05-17 17:02:10,429] Trial 6 finished with value: 0.7912593444508338 and parameters: {'iterations': 327, 'learning_rate': 0.048020302465356025, 'depth': 3, 'l2_leaf_reg': 88.51337714311498, 'bagging_temperature': 0.8329549396538749, 'random_strength': 0.9271369586977023, 'border_count': 165}. Best is trial 1 with value: 0.7987349051178838.\n[I 2024-05-17 17:03:41,550] Trial 7 finished with value: 0.7941345600920069 and parameters: {'iterations': 690, 'learning_rate': 0.07776066091935993, 'depth': 12, 'l2_leaf_reg': 37.631243317674034, 'bagging_temperature': 0.6733056844575928, 'random_strength': 0.38021441589794513, 'border_count': 202}. Best is trial 1 with value: 0.7987349051178838.\n[I 2024-05-17 17:03:45,556] Trial 8 finished with value: 0.7947096032202415 and parameters: {'iterations': 292, 'learning_rate': 0.19621474143242018, 'depth': 7, 'l2_leaf_reg': 19.83852844181212, 'bagging_temperature': 0.051790953344980184, 'random_strength': 0.3216214960320358, 'border_count': 131}. Best is trial 1 with value: 0.7987349051178838.\n[I 2024-05-17 17:05:38,352] Trial 9 finished with value: 0.7947096032202415 and parameters: {'iterations': 921, 'learning_rate': 0.07291042004636605, 'depth': 12, 'l2_leaf_reg': 75.71884925518403, 'bagging_temperature': 0.9715785730226246, 'random_strength': 0.4156189217473959, 'border_count': 178}. Best is trial 1 with value: 0.7987349051178838.\nBest hyperparameters: {'iterations': 811, 'learning_rate': 0.16120195322541006, 'depth': 4, 'l2_leaf_reg': 64.80933581315008, 'bagging_temperature': 0.5989308264972837, 'random_strength': 0.6045036910138146, 'border_count': 132}\nAccuracy on validation set: 0.7987349051178838\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.80      0.78      0.79       861\n           1       0.79      0.81      0.80       878\n\n    accuracy                           0.80      1739\n   macro avg       0.80      0.80      0.80      1739\nweighted avg       0.80      0.80      0.80      1739\n\nConfusion Matrix:\n [[675 186]\n [164 714]]\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/4cb24218-fce2-4b3d-97fa-3c3177aa8bdc","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715901181008,"execution_millis":217,"deepnote_to_be_reexecuted":false,"cell_id":"c65e1dd75874470ab70cb5385ff9d62d","deepnote_cell_type":"code"},"source":"# Evaluate the model\nprint(\"Accuracy:\", accuracy_score(y_val, y_pred_optimized))\nprint(\"Classification Report:\\n\", classification_report(y_val, y_pred_optimized))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred_optimized))","block_group":"6c32b2a0e6ec492d827dd0c9e4d63d05","execution_count":null,"outputs":[{"name":"stdout","text":"Accuracy: 0.8056354226566993\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.81      0.80      0.80       861\n           1       0.81      0.81      0.81       878\n\n    accuracy                           0.81      1739\n   macro avg       0.81      0.81      0.81      1739\nweighted avg       0.81      0.81      0.81      1739\n\nConfusion Matrix:\n [[690 171]\n [167 711]]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/d16eb5b0-de15-4ec4-a869-ef9e08b234ea","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"40db33778521477fa3bacdec2c3a0fba","deepnote_cell_type":"text-cell-h1"},"source":"# Bring the Data In","block_group":"0c79d79c638f4ac7a0e36c426c763934"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193623070,"execution_millis":376,"deepnote_to_be_reexecuted":false,"cell_id":"4a55c94c827e4c9ea2b52b3af43fad30","deepnote_cell_type":"code"},"source":"X_df = pd.read_csv('spaceship_train_X_v2.csv')\ny_df = pd.read_csv('spaceship_train_y.csv')\nX_submission = pd.read_csv('spaceship_test_X_v2.csv')\n\ny_df.drop('Unnamed: 0', axis=1, inplace=True)\nX_df.head()","block_group":"9acd7481bdec43f3ba43972876e9aaa0","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":39,"row_count":5,"columns":[{"name":"PassengerId","dtype":"object","stats":{"unique_count":5,"nan_count":0,"categories":[{"name":"0001_01","count":1},{"name":"0002_01","count":1},{"name":"3 others","count":3}]}},{"name":"CryoSleep","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"VIP","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":1}]}},{"name":"RoomService","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":"-0.3375298928969419","max":"0.1213487208940084","histogram":[{"bin_start":-0.3375298928969419,"bin_end":-0.2916420315178469,"count":2},{"bin_start":-0.2916420315178469,"bin_end":-0.24575417013875184,"count":1},{"bin_start":-0.24575417013875184,"bin_end":-0.19986630875965683,"count":0},{"bin_start":-0.19986630875965683,"bin_end":-0.1539784473805618,"count":1},{"bin_start":-0.1539784473805618,"bin_end":-0.10809058600146676,"count":0},{"bin_start":-0.10809058600146676,"bin_end":-0.06220272462237175,"count":0},{"bin_start":-0.06220272462237175,"bin_end":-0.01631486324327669,"count":0},{"bin_start":-0.01631486324327669,"bin_end":0.029572998135818318,"count":0},{"bin_start":0.029572998135818318,"bin_end":0.07546085951491333,"count":0},{"bin_start":0.07546085951491333,"bin_end":0.1213487208940084,"count":1}]}},{"name":"FoodCourt","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"-0.2838651282377854","max":"1.9566433495195388","histogram":[{"bin_start":-0.2838651282377854,"bin_end":-0.059814280462053004,"count":3},{"bin_start":-0.059814280462053004,"bin_end":0.16423656731367942,"count":0},{"bin_start":0.16423656731367942,"bin_end":0.3882874150894119,"count":0},{"bin_start":0.3882874150894119,"bin_end":0.6123382628651443,"count":1},{"bin_start":0.6123382628651443,"bin_end":0.8363891106408766,"count":0},{"bin_start":0.8363891106408766,"bin_end":1.0604399584166093,"count":0},{"bin_start":1.0604399584166093,"bin_end":1.2844908061923417,"count":0},{"bin_start":1.2844908061923417,"bin_end":1.508541653968074,"count":0},{"bin_start":1.508541653968074,"bin_end":1.7325925017438064,"count":0},{"bin_start":1.7325925017438064,"bin_end":1.9566433495195388,"count":1}]}},{"name":"ShoppingMall","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":"-0.2873829429551493","max":"0.3332397845143109","histogram":[{"bin_start":-0.2873829429551493,"bin_end":-0.2253206702082033,"count":3},{"bin_start":-0.2253206702082033,"bin_end":-0.16325839746125728,"count":0},{"bin_start":-0.16325839746125728,"bin_end":-0.10119612471431128,"count":0},{"bin_start":-0.10119612471431128,"bin_end":-0.03913385196736524,"count":0},{"bin_start":-0.03913385196736524,"bin_end":0.022928420779580794,"count":1},{"bin_start":0.022928420779580794,"bin_end":0.08499069352652677,"count":0},{"bin_start":0.08499069352652677,"bin_end":0.1470529662734728,"count":0},{"bin_start":0.1470529662734728,"bin_end":0.20911523902041884,"count":0},{"bin_start":0.20911523902041884,"bin_end":0.2711775117673648,"count":0},{"bin_start":0.2711775117673648,"bin_end":0.3332397845143109,"count":1}]}},{"name":"Spa","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"-0.2738262777680785","max":"5.692511954386446","histogram":[{"bin_start":-0.2738262777680785,"bin_end":0.32280754544737394,"count":3},{"bin_start":0.32280754544737394,"bin_end":0.9194413686628264,"count":0},{"bin_start":0.9194413686628264,"bin_end":1.5160751918782789,"count":0},{"bin_start":1.5160751918782789,"bin_end":2.1127090150937313,"count":0},{"bin_start":2.1127090150937313,"bin_end":2.7093428383091838,"count":1},{"bin_start":2.7093428383091838,"bin_end":3.305976661524636,"count":0},{"bin_start":3.305976661524636,"bin_end":3.902610484740089,"count":0},{"bin_start":3.902610484740089,"bin_end":4.499244307955541,"count":0},{"bin_start":4.499244307955541,"bin_end":5.095878131170993,"count":0},{"bin_start":5.095878131170993,"bin_end":5.692511954386446,"count":1}]}},{"name":"VRDeck","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"-0.2658309074152016","max":"-0.0956509707084443","histogram":[{"bin_start":-0.2658309074152016,"bin_end":-0.24881291374452588,"count":2},{"bin_start":-0.24881291374452588,"bin_end":-0.23179492007385014,"count":0},{"bin_start":-0.23179492007385014,"bin_end":-0.21477692640317442,"count":2},{"bin_start":-0.21477692640317442,"bin_end":-0.19775893273249867,"count":0},{"bin_start":-0.19775893273249867,"bin_end":-0.18074093906182295,"count":0},{"bin_start":-0.18074093906182295,"bin_end":-0.16372294539114723,"count":0},{"bin_start":-0.16372294539114723,"bin_end":-0.1467049517204715,"count":0},{"bin_start":-0.1467049517204715,"bin_end":-0.12968695804979577,"count":0},{"bin_start":-0.12968695804979577,"bin_end":-0.11266896437912005,"count":0},{"bin_start":-0.11266896437912005,"bin_end":-0.0956509707084443,"count":1}]}},{"name":"Expenditure","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"-0.5183569229651437","max":"3.1745957912176115","histogram":[{"bin_start":-0.5183569229651437,"bin_end":-0.14906165154686818,"count":2},{"bin_start":-0.14906165154686818,"bin_end":0.22023361987140733,"count":1},{"bin_start":0.22023361987140733,"bin_end":0.5895288912896828,"count":0},{"bin_start":0.5895288912896828,"bin_end":0.9588241627079583,"count":0},{"bin_start":0.9588241627079583,"bin_end":1.328119434126234,"count":1},{"bin_start":1.328119434126234,"bin_end":1.6974147055445092,"count":0},{"bin_start":1.6974147055445092,"bin_end":2.066709976962785,"count":0},{"bin_start":2.066709976962785,"bin_end":2.4360052483810604,"count":0},{"bin_start":2.4360052483810604,"bin_end":2.805300519799336,"count":0},{"bin_start":2.805300519799336,"bin_end":3.1745957912176115,"count":1}]}},{"name":"NoSpending","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":1}]}},{"name":"Group","dtype":"int64","stats":{"unique_count":4,"nan_count":0,"min":"1","max":"4","histogram":[{"bin_start":1,"bin_end":1.3,"count":1},{"bin_start":1.3,"bin_end":1.6,"count":0},{"bin_start":1.6,"bin_end":1.9,"count":0},{"bin_start":1.9,"bin_end":2.2,"count":1},{"bin_start":2.2,"bin_end":2.5,"count":0},{"bin_start":2.5,"bin_end":2.8,"count":0},{"bin_start":2.8,"bin_end":3.1,"count":2},{"bin_start":3.1,"bin_end":3.4,"count":0},{"bin_start":3.4,"bin_end":3.6999999999999997,"count":0},{"bin_start":3.6999999999999997,"bin_end":4,"count":1}]}},{"name":"GroupSize","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"1","max":"2","histogram":[{"bin_start":1,"bin_end":1.1,"count":3},{"bin_start":1.1,"bin_end":1.2,"count":0},{"bin_start":1.2,"bin_end":1.3,"count":0},{"bin_start":1.3,"bin_end":1.4,"count":0},{"bin_start":1.4,"bin_end":1.5,"count":0},{"bin_start":1.5,"bin_end":1.6,"count":0},{"bin_start":1.6,"bin_end":1.7000000000000002,"count":0},{"bin_start":1.7000000000000002,"bin_end":1.8,"count":0},{"bin_start":1.8,"bin_end":1.9,"count":0},{"bin_start":1.9,"bin_end":2,"count":2}]}},{"name":"Solo","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":2},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":3}]}},{"name":"CabinRegion_1","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"1","max":"1","histogram":[{"bin_start":0.5,"bin_end":0.6,"count":0},{"bin_start":0.6,"bin_end":0.7,"count":0},{"bin_start":0.7,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":0},{"bin_start":1,"bin_end":1.1,"count":5},{"bin_start":1.1,"bin_end":1.2000000000000002,"count":0},{"bin_start":1.2000000000000002,"bin_end":1.3,"count":0},{"bin_start":1.3,"bin_end":1.4,"count":0},{"bin_start":1.4,"bin_end":1.5,"count":0}]}},{"name":"CabinRegion_2","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinRegion_3","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinRegion_4","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinRegion_5","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinRegion_6","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinRegion_7","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"FamilySize","dtype":"int64","stats":{"unique_count":3,"nan_count":0,"min":"4","max":"9","histogram":[{"bin_start":4,"bin_end":4.5,"count":2},{"bin_start":4.5,"bin_end":5,"count":0},{"bin_start":5,"bin_end":5.5,"count":0},{"bin_start":5.5,"bin_end":6,"count":0},{"bin_start":6,"bin_end":6.5,"count":0},{"bin_start":6.5,"bin_end":7,"count":0},{"bin_start":7,"bin_end":7.5,"count":2},{"bin_start":7.5,"bin_end":8,"count":0},{"bin_start":8,"bin_end":8.5,"count":0},{"bin_start":8.5,"bin_end":9,"count":1}]}},{"name":"HomePlanet_Earth","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":3},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":2}]}},{"name":"HomePlanet_Europa","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":2},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":3}]}},{"name":"HomePlanet_Mars","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"Destination_55 Cancri e","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"Destination_PSO J318.5-22","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"Destination_TRAPPIST-1e","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"1","max":"1","histogram":[{"bin_start":0.5,"bin_end":0.6,"count":0},{"bin_start":0.6,"bin_end":0.7,"count":0},{"bin_start":0.7,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":0},{"bin_start":1,"bin_end":1.1,"count":5},{"bin_start":1.1,"bin_end":1.2000000000000002,"count":0},{"bin_start":1.2000000000000002,"bin_end":1.3,"count":0},{"bin_start":1.3,"bin_end":1.4,"count":0},{"bin_start":1.4,"bin_end":1.5,"count":0}]}},{"name":"CabinSide_P","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":1}]}},{"name":"CabinSide_S","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":4}]}},{"name":"CabinSide_Z","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinDeck_A","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":3},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":2}]}},{"name":"CabinDeck_B","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":1}]}},{"name":"CabinDeck_C","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinDeck_D","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinDeck_E","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinDeck_F","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":3},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":2}]}},{"name":"CabinDeck_G","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"CabinDeck_T","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"0","max":"0","histogram":[{"bin_start":-0.5,"bin_end":-0.4,"count":0},{"bin_start":-0.4,"bin_end":-0.3,"count":0},{"bin_start":-0.3,"bin_end":-0.19999999999999996,"count":0},{"bin_start":-0.19999999999999996,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.10000000000000009,"count":5},{"bin_start":0.10000000000000009,"bin_end":0.20000000000000007,"count":0},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0}]}},{"name":"AgeEncoded","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":"1.0","max":"4.0","histogram":[{"bin_start":1,"bin_end":1.3,"count":1},{"bin_start":1.3,"bin_end":1.6,"count":0},{"bin_start":1.6,"bin_end":1.9,"count":0},{"bin_start":1.9,"bin_end":2.2,"count":2},{"bin_start":2.2,"bin_end":2.5,"count":0},{"bin_start":2.5,"bin_end":2.8,"count":0},{"bin_start":2.8,"bin_end":3.1,"count":1},{"bin_start":3.1,"bin_end":3.4,"count":0},{"bin_start":3.4,"bin_end":3.6999999999999997,"count":0},{"bin_start":3.6999999999999997,"bin_end":4,"count":1}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"PassengerId":"0001_01","CryoSleep":0,"VIP":0,"RoomService":-0.3375298928969419,"FoodCourt":-0.2838651282377854,"ShoppingMall":-0.2873829429551493,"Spa":-0.2738262777680785,"VRDeck":-0.2658309074152016,"Expenditure":-0.5183569229651437,"NoSpending":1,"Group":1,"GroupSize":1,"Solo":1,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":4,"HomePlanet_Earth":0,"HomePlanet_Europa":1,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":1,"CabinSide_S":0,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":1,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":3,"_deepnote_index_column":0},{"PassengerId":"0002_01","CryoSleep":0,"VIP":0,"RoomService":-0.1724547480018475,"FoodCourt":-0.2782262646192686,"ShoppingMall":-0.2455620044464256,"Spa":0.2139651875264611,"VRDeck":-0.2270334088913813,"Expenditure":-0.2565815981420186,"NoSpending":0,"Group":2,"GroupSize":1,"Solo":1,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":4,"HomePlanet_Earth":1,"HomePlanet_Europa":0,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":0,"CabinSide_S":1,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":1,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":2,"_deepnote_index_column":1},{"PassengerId":"0003_01","CryoSleep":0,"VIP":1,"RoomService":-0.2724085054612624,"FoodCourt":1.9566433495195388,"ShoppingMall":-0.2873829429551493,"Spa":5.692511954386446,"VRDeck":-0.2226246022409472,"Expenditure":3.1745957912176115,"NoSpending":0,"Group":3,"GroupSize":2,"Solo":0,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":7,"HomePlanet_Earth":0,"HomePlanet_Europa":1,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":0,"CabinSide_S":1,"CabinSide_Z":0,"CabinDeck_A":1,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":4,"_deepnote_index_column":2},{"PassengerId":"0003_02","CryoSleep":0,"VIP":0,"RoomService":-0.3375298928969419,"FoodCourt":0.5199862076018809,"ShoppingMall":0.3332397845143109,"Spa":2.6840203305479915,"VRDeck":-0.0956509707084443,"Expenditure":1.3226065026931382,"NoSpending":0,"Group":3,"GroupSize":2,"Solo":0,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":7,"HomePlanet_Earth":0,"HomePlanet_Europa":1,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":0,"CabinSide_S":1,"CabinSide_Z":0,"CabinDeck_A":1,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":0,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":2,"_deepnote_index_column":3},{"PassengerId":"0004_01","CryoSleep":0,"VIP":0,"RoomService":0.1213487208940084,"FoodCourt":-0.2400073000937662,"ShoppingMall":-0.0347844743624579,"Spa":0.2281813322344987,"VRDeck":-0.264067384755028,"Expenditure":-0.1303176846743428,"NoSpending":0,"Group":4,"GroupSize":1,"Solo":1,"CabinRegion_1":1,"CabinRegion_2":0,"CabinRegion_3":0,"CabinRegion_4":0,"CabinRegion_5":0,"CabinRegion_6":0,"CabinRegion_7":0,"FamilySize":9,"HomePlanet_Earth":1,"HomePlanet_Europa":0,"HomePlanet_Mars":0,"Destination_55 Cancri e":0,"Destination_PSO J318.5-22":0,"Destination_TRAPPIST-1e":1,"CabinSide_P":0,"CabinSide_S":1,"CabinSide_Z":0,"CabinDeck_A":0,"CabinDeck_B":0,"CabinDeck_C":0,"CabinDeck_D":0,"CabinDeck_E":0,"CabinDeck_F":1,"CabinDeck_G":0,"CabinDeck_T":0,"AgeEncoded":1,"_deepnote_index_column":4}]},"text/plain":"  PassengerId  CryoSleep  VIP  RoomService  FoodCourt  ShoppingMall       Spa  \\\n0     0001_01          0    0    -0.337530  -0.283865     -0.287383 -0.273826   \n1     0002_01          0    0    -0.172455  -0.278226     -0.245562  0.213965   \n2     0003_01          0    1    -0.272409   1.956643     -0.287383  5.692512   \n3     0003_02          0    0    -0.337530   0.519986      0.333240  2.684020   \n4     0004_01          0    0     0.121349  -0.240007     -0.034784  0.228181   \n\n     VRDeck  Expenditure  NoSpending  ...  CabinSide_Z  CabinDeck_A  \\\n0 -0.265831    -0.518357           1  ...            0            0   \n1 -0.227033    -0.256582           0  ...            0            0   \n2 -0.222625     3.174596           0  ...            0            1   \n3 -0.095651     1.322607           0  ...            0            1   \n4 -0.264067    -0.130318           0  ...            0            0   \n\n   CabinDeck_B  CabinDeck_C  CabinDeck_D  CabinDeck_E  CabinDeck_F  \\\n0            1            0            0            0            0   \n1            0            0            0            0            1   \n2            0            0            0            0            0   \n3            0            0            0            0            0   \n4            0            0            0            0            1   \n\n   CabinDeck_G  CabinDeck_T  AgeEncoded  \n0            0            0         3.0  \n1            0            0         2.0  \n2            0            0         4.0  \n3            0            0         2.0  \n4            0            0         1.0  \n\n[5 rows x 39 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>CryoSleep</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Expenditure</th>\n      <th>NoSpending</th>\n      <th>...</th>\n      <th>CabinSide_Z</th>\n      <th>CabinDeck_A</th>\n      <th>CabinDeck_B</th>\n      <th>CabinDeck_C</th>\n      <th>CabinDeck_D</th>\n      <th>CabinDeck_E</th>\n      <th>CabinDeck_F</th>\n      <th>CabinDeck_G</th>\n      <th>CabinDeck_T</th>\n      <th>AgeEncoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001_01</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.337530</td>\n      <td>-0.283865</td>\n      <td>-0.287383</td>\n      <td>-0.273826</td>\n      <td>-0.265831</td>\n      <td>-0.518357</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002_01</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.172455</td>\n      <td>-0.278226</td>\n      <td>-0.245562</td>\n      <td>0.213965</td>\n      <td>-0.227033</td>\n      <td>-0.256582</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0003_01</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-0.272409</td>\n      <td>1.956643</td>\n      <td>-0.287383</td>\n      <td>5.692512</td>\n      <td>-0.222625</td>\n      <td>3.174596</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0003_02</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.337530</td>\n      <td>0.519986</td>\n      <td>0.333240</td>\n      <td>2.684020</td>\n      <td>-0.095651</td>\n      <td>1.322607</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0004_01</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.121349</td>\n      <td>-0.240007</td>\n      <td>-0.034784</td>\n      <td>0.228181</td>\n      <td>-0.264067</td>\n      <td>-0.130318</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/c60a369e-0b15-4526-975d-b0ff0242b75e","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193623473,"execution_millis":299,"deepnote_to_be_reexecuted":false,"cell_id":"4b98e49633d74048b0fbfd1510ba4db1","deepnote_cell_type":"code"},"source":"from sklearn.model_selection import train_test_split\n\n# Memisahkan data menjadi train dan validation set\nX_train, X_val, y_train, y_val = train_test_split(X_df, y_df, test_size=0.2, random_state=42)\n# Mengubah target menjadi 1D array\ny_train = y_train['Transported'].values\ny_test = y_val['Transported'].values","block_group":"f3e98e79ef544fb98587f50a6297debd","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"64808c9f8f764a57b514c224061accc6","deepnote_cell_type":"text-cell-h1"},"source":"# Model Training","block_group":"e01f12f006324577a8685ffcb2e53c45"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193623474,"execution_millis":298,"deepnote_to_be_reexecuted":false,"cell_id":"d2c8f569859143bcae76ad309e2454e4","deepnote_cell_type":"code"},"source":"\n# Membuat pipeline\n\npipeline = Pipeline([\n    ('scaler', MinMaxScaler()),\n    ('classifier', LGBMClassifier(random_state=42))\n])\n\n\n\nparam_grid = {\n    'classifier__n_estimators': [500],\n    'classifier__max_depth': [10],\n    'classifier__learning_rate': [0.01],\n    'classifier__subsample': [0.8],\n    'classifier__colsample_bytree': [1]\n}\n\n# Menggunakan StratifiedKFold untuk handling imbalanced data\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","block_group":"ffa1a5a6dc0742f6a823ee9eafca1c28","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193623508,"execution_millis":6871,"deepnote_to_be_reexecuted":false,"cell_id":"d652a707358f4e95bca9af87b903c3e2","deepnote_cell_type":"code"},"source":"# Membuat GridSearchCV dengan cv yang lebih robust\ngrid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='accuracy', verbose=1)\ngrid_search.fit(X_train, y_train)\n\n# Menampilkan parameter terbaik dan skor\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))","block_group":"f25cc19a7dc748ebb5ccf17f344e75e3","execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 10 folds for each of 1 candidates, totalling 10 fits\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3108\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000606 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6258, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503356 -> initscore=0.013423\n[LightGBM] [Info] Start training from score 0.013423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3108\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000704 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6258, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503356 -> initscore=0.013423\n[LightGBM] [Info] Start training from score 0.013423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3108\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6258, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503356 -> initscore=0.013423\n[LightGBM] [Info] Start training from score 0.013423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3108\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000664 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6258, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503356 -> initscore=0.013423\n[LightGBM] [Info] Start training from score 0.013423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3109\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6259, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503275 -> initscore=0.013101\n[LightGBM] [Info] Start training from score 0.013101\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3109\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6259, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503275 -> initscore=0.013101\n[LightGBM] [Info] Start training from score 0.013101\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3109\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6259, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503275 -> initscore=0.013101\n[LightGBM] [Info] Start training from score 0.013101\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3109\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6259, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503275 -> initscore=0.013101\n[LightGBM] [Info] Start training from score 0.013101\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3109\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6259, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503275 -> initscore=0.013101\n[LightGBM] [Info] Start training from score 0.013101\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3150, number of negative: 3109\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6259, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503275 -> initscore=0.013101\n[LightGBM] [Info] Start training from score 0.013101\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000841 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n[LightGBM] [Info] Start training from score 0.013230\nBest parameters: {'classifier__colsample_bytree': 1, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 10, 'classifier__n_estimators': 500, 'classifier__subsample': 0.8}\nBest cross-validation score: 0.81\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/80bae36e-6a43-4978-8fa5-4980984adac7","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193630388,"execution_millis":8020,"deepnote_to_be_reexecuted":false,"cell_id":"3c8b537f12fe48bda4e12838a1809532","deepnote_cell_type":"code"},"source":"# Menggunakan estimator terbaik untuk prediksi pada data test\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_val)\n\n# Evaluasi model pada data test\nprint(\"Accuracy on test set:\", accuracy_score(y_val, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_val, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n\n# Fit the model on all training data\ngrid_search.fit(X_df, y_df)","block_group":"1f877861536747488f387d65084fb3b1","execution_count":null,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\nAccuracy on test set: 0.7993099482461185\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.81      0.78      0.79       861\n           1       0.79      0.82      0.80       878\n\n    accuracy                           0.80      1739\n   macro avg       0.80      0.80      0.80      1739\nweighted avg       0.80      0.80      0.80      1739\n\nConfusion Matrix:\n [[671 190]\n [159 719]]\nFitting 10 folds for each of 1 candidates, totalling 10 fits\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000862 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000846 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000845 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n[LightGBM] [Info] Start training from score 0.014826\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000833 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n[LightGBM] [Info] Start training from score 0.014826\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000660 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000850 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000838 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000843 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000846 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000941 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n[LightGBM] [Info] Start training from score 0.014495\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n             estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n                                       ('classifier',\n                                        LGBMClassifier(random_state=42))]),\n             param_grid={'classifier__colsample_bytree': [1],\n                         'classifier__learning_rate': [0.01],\n                         'classifier__max_depth': [10],\n                         'classifier__n_estimators': [500],\n                         'classifier__subsample': [0.8]},\n             scoring='accuracy', verbose=1)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n                                       (&#x27;classifier&#x27;,\n                                        LGBMClassifier(random_state=42))]),\n             param_grid={&#x27;classifier__colsample_bytree&#x27;: [1],\n                         &#x27;classifier__learning_rate&#x27;: [0.01],\n                         &#x27;classifier__max_depth&#x27;: [10],\n                         &#x27;classifier__n_estimators&#x27;: [500],\n                         &#x27;classifier__subsample&#x27;: [0.8]},\n             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n                                       (&#x27;classifier&#x27;,\n                                        LGBMClassifier(random_state=42))]),\n             param_grid={&#x27;classifier__colsample_bytree&#x27;: [1],\n                         &#x27;classifier__learning_rate&#x27;: [0.01],\n                         &#x27;classifier__max_depth&#x27;: [10],\n                         &#x27;classifier__n_estimators&#x27;: [500],\n                         &#x27;classifier__subsample&#x27;: [0.8]},\n             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n                (&#x27;classifier&#x27;, LGBMClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/0739ac49-4e18-4288-823f-47d2b57d9720","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0da25c919d764cdeb49416dcd463bd89","deepnote_cell_type":"text-cell-h1"},"source":"# Submission Prediction","block_group":"4c856cb090fc4ca8847589c39997e4a2"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193638417,"execution_millis":8164,"deepnote_to_be_reexecuted":false,"cell_id":"0828f6164172498cb9749a86f979464a","deepnote_cell_type":"code"},"source":"# For training, we use ALL data from spaceship_train_X_v2.csv and spaceship_train_y.csv\ngrid_search.fit(X_df, y_df['Transported'].values)\n# Prediksi data submission\ny_prediction = grid_search.predict(X_submission)\nprint(y_prediction)\n","block_group":"51e9e9b1a74b47e3beec7c41ad94151c","execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 10 folds for each of 1 candidates, totalling 10 fits\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000703 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000879 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000870 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n[LightGBM] [Info] Start training from score 0.014573\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000897 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n[LightGBM] [Info] Start training from score 0.014826\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000875 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n[LightGBM] [Info] Start training from score 0.014826\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000665 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000924 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001078 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000918 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000834 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n[LightGBM] [Info] Start training from score 0.014315\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001095 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2126\n[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 38\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n[LightGBM] [Info] Start training from score 0.014495\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[1 0 1 ... 1 1 1]\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/ebdae48e-73ef-4130-ab0a-e5217674efe6","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715193646591,"execution_millis":568,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":100,"pageIndex":0},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"cell_id":"6a7c4fc8a5304e44902870f24aeac79e","deepnote_cell_type":"code"},"source":"submission_dict = {'PassengerId':X_submission['PassengerId'], 'Transported':y_prediction.astype('bool')}\nsubmission_dict = pd.DataFrame(submission_dict)\nsubmission_dict","block_group":"dd269131f3a14a0d86bd4f70d52f78ba","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":2,"row_count":4277,"columns":[{"name":"PassengerId","dtype":"object","stats":{"unique_count":4277,"nan_count":0,"categories":[{"name":"0013_01","count":1},{"name":"0018_01","count":1},{"name":"4275 others","count":4275}]}},{"name":"Transported","dtype":"bool","stats":{"unique_count":2,"nan_count":0,"categories":[{"name":"False","count":2179},{"name":"True","count":2098}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"PassengerId":"0013_01","Transported":"True","_deepnote_index_column":0},{"PassengerId":"0018_01","Transported":"False","_deepnote_index_column":1},{"PassengerId":"0019_01","Transported":"True","_deepnote_index_column":2},{"PassengerId":"0021_01","Transported":"True","_deepnote_index_column":3},{"PassengerId":"0023_01","Transported":"True","_deepnote_index_column":4},{"PassengerId":"0027_01","Transported":"True","_deepnote_index_column":5},{"PassengerId":"0029_01","Transported":"True","_deepnote_index_column":6},{"PassengerId":"0032_01","Transported":"True","_deepnote_index_column":7},{"PassengerId":"0032_02","Transported":"True","_deepnote_index_column":8},{"PassengerId":"0033_01","Transported":"True","_deepnote_index_column":9},{"PassengerId":"0037_01","Transported":"False","_deepnote_index_column":10},{"PassengerId":"0040_01","Transported":"False","_deepnote_index_column":11},{"PassengerId":"0040_02","Transported":"False","_deepnote_index_column":12},{"PassengerId":"0042_01","Transported":"False","_deepnote_index_column":13},{"PassengerId":"0046_01","Transported":"False","_deepnote_index_column":14},{"PassengerId":"0046_02","Transported":"False","_deepnote_index_column":15},{"PassengerId":"0046_03","Transported":"False","_deepnote_index_column":16},{"PassengerId":"0047_01","Transported":"True","_deepnote_index_column":17},{"PassengerId":"0047_02","Transported":"True","_deepnote_index_column":18},{"PassengerId":"0047_03","Transported":"False","_deepnote_index_column":19},{"PassengerId":"0048_01","Transported":"True","_deepnote_index_column":20},{"PassengerId":"0049_01","Transported":"False","_deepnote_index_column":21},{"PassengerId":"0054_01","Transported":"True","_deepnote_index_column":22},{"PassengerId":"0054_02","Transported":"True","_deepnote_index_column":23},{"PassengerId":"0054_03","Transported":"False","_deepnote_index_column":24},{"PassengerId":"0055_01","Transported":"False","_deepnote_index_column":25},{"PassengerId":"0057_01","Transported":"True","_deepnote_index_column":26},{"PassengerId":"0059_01","Transported":"True","_deepnote_index_column":27},{"PassengerId":"0060_01","Transported":"False","_deepnote_index_column":28},{"PassengerId":"0063_01","Transported":"True","_deepnote_index_column":29},{"PassengerId":"0065_01","Transported":"True","_deepnote_index_column":30},{"PassengerId":"0075_01","Transported":"False","_deepnote_index_column":31},{"PassengerId":"0079_01","Transported":"True","_deepnote_index_column":32},{"PassengerId":"0080_01","Transported":"False","_deepnote_index_column":33},{"PassengerId":"0083_01","Transported":"False","_deepnote_index_column":34},{"PassengerId":"0087_01","Transported":"False","_deepnote_index_column":35},{"PassengerId":"0089_01","Transported":"True","_deepnote_index_column":36},{"PassengerId":"0093_01","Transported":"True","_deepnote_index_column":37},{"PassengerId":"0094_01","Transported":"True","_deepnote_index_column":38},{"PassengerId":"0094_02","Transported":"False","_deepnote_index_column":39},{"PassengerId":"0095_01","Transported":"True","_deepnote_index_column":40},{"PassengerId":"0096_01","Transported":"False","_deepnote_index_column":41},{"PassengerId":"0100_01","Transported":"True","_deepnote_index_column":42},{"PassengerId":"0100_02","Transported":"False","_deepnote_index_column":43},{"PassengerId":"0104_01","Transported":"False","_deepnote_index_column":44},{"PassengerId":"0106_01","Transported":"True","_deepnote_index_column":45},{"PassengerId":"0109_01","Transported":"False","_deepnote_index_column":46},{"PassengerId":"0117_01","Transported":"False","_deepnote_index_column":47},{"PassengerId":"0118_01","Transported":"False","_deepnote_index_column":48},{"PassengerId":"0121_01","Transported":"False","_deepnote_index_column":49},{"PassengerId":"0124_01","Transported":"True","_deepnote_index_column":50},{"PassengerId":"0125_01","Transported":"True","_deepnote_index_column":51},{"PassengerId":"0125_02","Transported":"False","_deepnote_index_column":52},{"PassengerId":"0130_01","Transported":"True","_deepnote_index_column":53},{"PassengerId":"0131_01","Transported":"False","_deepnote_index_column":54},{"PassengerId":"0132_01","Transported":"True","_deepnote_index_column":55},{"PassengerId":"0135_01","Transported":"False","_deepnote_index_column":56},{"PassengerId":"0137_01","Transported":"True","_deepnote_index_column":57},{"PassengerId":"0142_01","Transported":"True","_deepnote_index_column":58},{"PassengerId":"0142_02","Transported":"False","_deepnote_index_column":59},{"PassengerId":"0142_03","Transported":"True","_deepnote_index_column":60},{"PassengerId":"0143_01","Transported":"True","_deepnote_index_column":61},{"PassengerId":"0145_01","Transported":"False","_deepnote_index_column":62},{"PassengerId":"0150_01","Transported":"True","_deepnote_index_column":63},{"PassengerId":"0150_02","Transported":"True","_deepnote_index_column":64},{"PassengerId":"0153_01","Transported":"False","_deepnote_index_column":65},{"PassengerId":"0154_01","Transported":"True","_deepnote_index_column":66},{"PassengerId":"0155_01","Transported":"False","_deepnote_index_column":67},{"PassengerId":"0156_01","Transported":"True","_deepnote_index_column":68},{"PassengerId":"0157_01","Transported":"False","_deepnote_index_column":69},{"PassengerId":"0158_01","Transported":"False","_deepnote_index_column":70},{"PassengerId":"0158_02","Transported":"True","_deepnote_index_column":71},{"PassengerId":"0159_01","Transported":"False","_deepnote_index_column":72},{"PassengerId":"0161_01","Transported":"False","_deepnote_index_column":73},{"PassengerId":"0162_01","Transported":"True","_deepnote_index_column":74},{"PassengerId":"0166_01","Transported":"True","_deepnote_index_column":75},{"PassengerId":"0168_01","Transported":"True","_deepnote_index_column":76},{"PassengerId":"0175_01","Transported":"False","_deepnote_index_column":77},{"PassengerId":"0175_02","Transported":"True","_deepnote_index_column":78},{"PassengerId":"0175_03","Transported":"False","_deepnote_index_column":79},{"PassengerId":"0175_04","Transported":"False","_deepnote_index_column":80},{"PassengerId":"0175_05","Transported":"False","_deepnote_index_column":81},{"PassengerId":"0176_01","Transported":"False","_deepnote_index_column":82},{"PassengerId":"0180_01","Transported":"False","_deepnote_index_column":83},{"PassengerId":"0184_01","Transported":"True","_deepnote_index_column":84},{"PassengerId":"0185_01","Transported":"True","_deepnote_index_column":85},{"PassengerId":"0187_01","Transported":"True","_deepnote_index_column":86},{"PassengerId":"0191_01","Transported":"False","_deepnote_index_column":87},{"PassengerId":"0194_01","Transported":"True","_deepnote_index_column":88},{"PassengerId":"0194_02","Transported":"True","_deepnote_index_column":89},{"PassengerId":"0194_03","Transported":"False","_deepnote_index_column":90},{"PassengerId":"0204_01","Transported":"False","_deepnote_index_column":91},{"PassengerId":"0208_01","Transported":"False","_deepnote_index_column":92},{"PassengerId":"0209_01","Transported":"False","_deepnote_index_column":93},{"PassengerId":"0214_01","Transported":"False","_deepnote_index_column":94},{"PassengerId":"0214_02","Transported":"False","_deepnote_index_column":95},{"PassengerId":"0215_01","Transported":"True","_deepnote_index_column":96},{"PassengerId":"0218_01","Transported":"False","_deepnote_index_column":97},{"PassengerId":"0226_01","Transported":"True","_deepnote_index_column":98},{"PassengerId":"0227_01","Transported":"True","_deepnote_index_column":99}]},"text/plain":"     PassengerId  Transported\n0        0013_01         True\n1        0018_01        False\n2        0019_01         True\n3        0021_01         True\n4        0023_01         True\n...          ...          ...\n4272     9266_02         True\n4273     9269_01        False\n4274     9271_01         True\n4275     9273_01         True\n4276     9277_01         True\n\n[4277 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Transported</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0013_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0018_01</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0019_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0021_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0023_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4272</th>\n      <td>9266_02</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4273</th>\n      <td>9269_01</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4274</th>\n      <td>9271_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4275</th>\n      <td>9273_01</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4276</th>\n      <td>9277_01</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>4277 rows × 2 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/40d9e1ac-c5d6-4b24-8ff4-92714e7e5f9c","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"5047c90a2a7d46598e22c34f90a821ea","deepnote_cell_type":"text-cell-h2"},"source":"## Export CSV","block_group":"11179e1880944debabb23367b2d4f7f0"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1715194401883,"execution_millis":145,"deepnote_to_be_reexecuted":false,"cell_id":"f94fb007d95c44b791aed86049e1623e","deepnote_cell_type":"code"},"source":"submission_dict.to_csv('spaceship_lightgbm6.csv', index=False)","block_group":"af3684a41e194ff4ba4e0fbc07d01dd3","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=2a79941c-6614-47fe-9427-0e9f23998893' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2024-05-17T17:30:29.626Z"},"deepnote_notebook_id":"f62b3f4e534e4a64b9e8b35e164d0443","deepnote_execution_queue":[]}}
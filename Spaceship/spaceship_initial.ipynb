{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('D:/BISMILLAHIRRAHMANIRRAHIM Informatics Engineering/SEMESTER 4/Mata Kuliah/Pengantar Pembelajaran Mesin/Project Battle/ppm-spaceship-titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
      "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
      "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
      "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
      "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
      "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
      "...          ...        ...       ...       ...            ...   ...    ...   \n",
      "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
      "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
      "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
      "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
      "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
      "\n",
      "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
      "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
      "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
      "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
      "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
      "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
      "...           ...        ...           ...     ...     ...                ...   \n",
      "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
      "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
      "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
      "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
      "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
      "\n",
      "      Transported  \n",
      "0           False  \n",
      "1            True  \n",
      "2           False  \n",
      "3           False  \n",
      "4            True  \n",
      "...           ...  \n",
      "8688        False  \n",
      "8689        False  \n",
      "8690         True  \n",
      "8691        False  \n",
      "8692         True  \n",
      "\n",
      "[8693 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet      201\n",
       "CryoSleep       217\n",
       "Cabin           199\n",
       "Destination     182\n",
       "Age             179\n",
       "VIP             203\n",
       "RoomService     181\n",
       "FoodCourt       183\n",
       "ShoppingMall    208\n",
       "Spa             183\n",
       "VRDeck          188\n",
       "Name            200\n",
       "Transported       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned_rows = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId     0\n",
      "HomePlanet      0\n",
      "CryoSleep       0\n",
      "Cabin           0\n",
      "Destination     0\n",
      "Age             0\n",
      "VIP             0\n",
      "RoomService     0\n",
      "FoodCourt       0\n",
      "ShoppingMall    0\n",
      "Spa             0\n",
      "VRDeck          0\n",
      "Name            0\n",
      "Transported     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_cleaned_rows.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tidak ada nilai NaN dalam dataset.\n"
     ]
    }
   ],
   "source": [
    "# Periksa apakah masih ada nilai NaN dalam dataset\n",
    "nan_values = data_cleaned_rows.isna().sum().sum()\n",
    "\n",
    "if nan_values == 0:\n",
    "    print(\"Tidak ada nilai NaN dalam dataset.\")\n",
    "else:\n",
    "    print(\"Masih ada nilai NaN dalam dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengonversi kolom CryoSleep, VIP, dan Transported menjadi tipe data boolean\n",
    "df['CryoSleep'] = df['CryoSleep'].astype(bool)\n",
    "df['VIP'] = df['VIP'].astype(bool)\n",
    "df['Transported'] = df['Transported'].astype(bool)\n",
    "\n",
    "# Mengonversi kolom Age menjadi tipe data numerik\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "\n",
    "# Melakukan penghapusan baris yang mengandung nilai kosong\n",
    "data_cleaned_rows = df.dropna(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6943 entries, 0 to 8692\n",
      "Columns: 5533 entries, PassengerId to Destination_TRAPPIST-1e\n",
      "dtypes: bool(5525), float64(6), object(2)\n",
      "memory usage: 37.1+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# One-hot encoding untuk atribut-atribut kategorikal\n",
    "data_cleaned_rows = pd.get_dummies(data_cleaned_rows, columns=['HomePlanet', 'Cabin', 'Destination'])\n",
    "\n",
    "# Periksa kembali informasi dataset setelah konversi\n",
    "data_cleaned_rows.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'CryoSleep', 'Age', 'VIP', 'RoomService', 'FoodCourt',\n",
      "       'ShoppingMall', 'Spa', 'VRDeck', 'Name',\n",
      "       ...\n",
      "       'Cabin_G/995/S', 'Cabin_G/996/S', 'Cabin_G/998/S', 'Cabin_G/999/P',\n",
      "       'Cabin_G/999/S', 'Cabin_T/1/P', 'Cabin_T/3/P',\n",
      "       'Destination_55 Cancri e', 'Destination_PSO J318.5-22',\n",
      "       'Destination_TRAPPIST-1e'],\n",
      "      dtype='object', length=5533)\n"
     ]
    }
   ],
   "source": [
    "print(data_cleaned_rows.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'CryoSleep', 'Age', 'VIP', 'RoomService', 'FoodCourt',\n",
      "       'ShoppingMall', 'Spa', 'VRDeck', 'Name',\n",
      "       ...\n",
      "       'Cabin_G/995/S', 'Cabin_G/996/S', 'Cabin_G/998/S', 'Cabin_G/999/P',\n",
      "       'Cabin_G/999/S', 'Cabin_T/1/P', 'Cabin_T/3/P',\n",
      "       'Destination_55 Cancri e', 'Destination_PSO J318.5-22',\n",
      "       'Destination_TRAPPIST-1e'],\n",
      "      dtype='object', length=5533)\n"
     ]
    }
   ],
   "source": [
    "print(data_cleaned_rows.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Pisahkan fitur dan target\n",
    "X = data_cleaned_rows.drop(['PassengerId', 'Name', 'Transported'], axis=1)\n",
    "y = data_cleaned_rows['Transported']\n",
    "\n",
    "# Bagi dataset menjadi dataset pelatihan dan dataset pengujian (80% pelatihan, 20% pengujian)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes model: 0.6263498920086393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Inisialisasi model Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Latih model Naive Bayes\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Lakukan prediksi dengan model Naive Bayes pada dataset pengujian\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluasi kinerja model Naive Bayes\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "print(\"Accuracy of Naive Bayes model:\", nb_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN model: 0.7710583153347732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Inisialisasi model KNN\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Latih model KNN\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Lakukan prediksi dengan model KNN pada dataset pengujian\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluasi kinerja model KNN\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "print(\"Accuracy of KNN model:\", knn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Simpan model KNN ke dalam file pickle\n",
    "with open('knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_classifier, f)\n",
    "\n",
    "# Simpan DataFrame data_cleaned_rows ke dalam file CSV yang baru\n",
    "data_cleaned_rows.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Muat kembali model KNN dari file pickle\n",
    "with open('knn_model.pkl', 'rb') as f:\n",
    "    loaded_knn_model = pickle.load(f)\n",
    "\n",
    "# 2. Muat data tes\n",
    "# Misalnya, jika Anda memiliki file CSV untuk data tes bernama 'test_data.csv'\n",
    "test_data = pd.read_csv('D:/BISMILLAHIRRAHMANIRRAHIM Informatics Engineering/SEMESTER 4/Mata Kuliah/Pengantar Pembelajaran Mesin/Project Battle/ppm-spaceship-titanic/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   4277 non-null   object \n",
      " 1   HomePlanet    4190 non-null   object \n",
      " 2   CryoSleep     4184 non-null   object \n",
      " 3   Cabin         4177 non-null   object \n",
      " 4   Destination   4185 non-null   object \n",
      " 5   Age           4186 non-null   float64\n",
      " 6   VIP           4184 non-null   object \n",
      " 7   RoomService   4195 non-null   float64\n",
      " 8   FoodCourt     4171 non-null   float64\n",
      " 9   ShoppingMall  4179 non-null   float64\n",
      " 10  Spa           4176 non-null   float64\n",
      " 11  VRDeck        4197 non-null   float64\n",
      " 12  Name          4183 non-null   object \n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 434.5+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet       87\n",
       "CryoSleep        93\n",
       "Cabin           100\n",
       "Destination      92\n",
       "Age              91\n",
       "VIP              93\n",
       "RoomService      82\n",
       "FoodCourt       106\n",
       "ShoppingMall     98\n",
       "Spa             101\n",
       "VRDeck           80\n",
       "Name             94\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = test_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     0\n",
       "HomePlanet      0\n",
       "CryoSleep       0\n",
       "Cabin           0\n",
       "Destination     0\n",
       "Age             0\n",
       "VIP             0\n",
       "RoomService     0\n",
       "FoodCourt       0\n",
       "ShoppingMall    0\n",
       "Spa             0\n",
       "VRDeck          0\n",
       "Name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3281 entries, 0 to 4276\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   3281 non-null   object \n",
      " 1   HomePlanet    3281 non-null   object \n",
      " 2   CryoSleep     3281 non-null   bool   \n",
      " 3   Cabin         3281 non-null   object \n",
      " 4   Destination   3281 non-null   object \n",
      " 5   Age           3281 non-null   float64\n",
      " 6   VIP           3281 non-null   int32  \n",
      " 7   RoomService   3281 non-null   float64\n",
      " 8   FoodCourt     3281 non-null   float64\n",
      " 9   ShoppingMall  3281 non-null   float64\n",
      " 10  Spa           3281 non-null   float64\n",
      " 11  VRDeck        3281 non-null   float64\n",
      " 12  Name          3281 non-null   object \n",
      "dtypes: bool(1), float64(6), int32(1), object(5)\n",
      "memory usage: 323.6+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHMAD ZAKI\\AppData\\Local\\Temp\\ipykernel_38728\\876334592.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['CryoSleep'] = pd.to_numeric(data_clean['CryoSleep'])\n",
      "C:\\Users\\AHMAD ZAKI\\AppData\\Local\\Temp\\ipykernel_38728\\876334592.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['VIP'] = data_clean['VIP'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3281 entries, 0 to 4276\n",
      "Columns: 2689 entries, PassengerId to Destination_TRAPPIST-1e\n",
      "dtypes: bool(2680), float64(6), int32(1), object(2)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Mengonversi kolom CryoSleep menjadi tipe data numerik\n",
    "data_clean['CryoSleep'] = pd.to_numeric(data_clean['CryoSleep'])\n",
    "\n",
    "# Mengonversi kolom VIP menjadi tipe data numerik (asumsi nilai True menjadi 1 dan False menjadi 0)\n",
    "data_clean['VIP'] = data_clean['VIP'].astype(int)\n",
    "\n",
    "# Periksa kembali informasi dataset setelah konversi\n",
    "data_clean.info()\n",
    "# One-hot encoding untuk atribut-atribut kategorikal\n",
    "data_clean = pd.get_dummies(data_clean, columns=['HomePlanet', 'Cabin', 'Destination'])\n",
    "\n",
    "# Periksa kembali informasi dataset setelah konversi\n",
    "data_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_G/995/P</th>\n",
       "      <th>Cabin_G/996/P</th>\n",
       "      <th>Cabin_G/997/S</th>\n",
       "      <th>Cabin_T/0/S</th>\n",
       "      <th>Cabin_T/1/S</th>\n",
       "      <th>Cabin_T/3/S</th>\n",
       "      <th>Cabin_T/4/P</th>\n",
       "      <th>Destination_55 Cancri e</th>\n",
       "      <th>Destination_PSO J318.5-22</th>\n",
       "      <th>Destination_TRAPPIST-1e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nelly Carsoning</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Peckers</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sabih Unhearfus</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>False</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Meratz Caltilter</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brence Harperez</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2689 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  CryoSleep   Age  VIP  RoomService  FoodCourt  ShoppingMall  \\\n",
       "0     0013_01       True  27.0    0          0.0        0.0           0.0   \n",
       "1     0018_01      False  19.0    0          0.0        9.0           0.0   \n",
       "2     0019_01       True  31.0    0          0.0        0.0           0.0   \n",
       "3     0021_01      False  38.0    0          0.0     6652.0           0.0   \n",
       "4     0023_01      False  20.0    0         10.0        0.0         635.0   \n",
       "\n",
       "      Spa  VRDeck              Name  ...  Cabin_G/995/P  Cabin_G/996/P  \\\n",
       "0     0.0     0.0   Nelly Carsoning  ...          False          False   \n",
       "1  2823.0     0.0    Lerome Peckers  ...          False          False   \n",
       "2     0.0     0.0   Sabih Unhearfus  ...          False          False   \n",
       "3   181.0   585.0  Meratz Caltilter  ...          False          False   \n",
       "4     0.0     0.0   Brence Harperez  ...          False          False   \n",
       "\n",
       "   Cabin_G/997/S  Cabin_T/0/S  Cabin_T/1/S  Cabin_T/3/S  Cabin_T/4/P  \\\n",
       "0          False        False        False        False        False   \n",
       "1          False        False        False        False        False   \n",
       "2          False        False        False        False        False   \n",
       "3          False        False        False        False        False   \n",
       "4          False        False        False        False        False   \n",
       "\n",
       "   Destination_55 Cancri e  Destination_PSO J318.5-22  Destination_TRAPPIST-1e  \n",
       "0                    False                      False                     True  \n",
       "1                    False                      False                     True  \n",
       "2                     True                      False                    False  \n",
       "3                    False                      False                     True  \n",
       "4                    False                      False                     True  \n",
       "\n",
       "[5 rows x 2689 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryoSleep                    0\n",
      "Age                          0\n",
      "VIP                          0\n",
      "RoomService                  0\n",
      "FoodCourt                    0\n",
      "                            ..\n",
      "Cabin_T/1/P                  0\n",
      "Cabin_T/3/P                  0\n",
      "Destination_55 Cancri e      0\n",
      "Destination_PSO J318.5-22    0\n",
      "Destination_TRAPPIST-1e      0\n",
      "Length: 5530, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = X_test.isnull().sum()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Cabin\n- Destination\n- HomePlanet\nFeature names seen at fit time, yet now missing:\n- Cabin_A/0/P\n- Cabin_A/0/S\n- Cabin_A/1/S\n- Cabin_A/10/P\n- Cabin_A/10/S\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     knn_model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 5. Lakukan prediksi pada data test set\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m predicted_transported \u001b[38;5;241m=\u001b[39m \u001b[43mknn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 6. Simpan hasil prediksi ke dalam file CSV\u001b[39;00m\n\u001b[0;32m     23\u001b[0m df_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m'\u001b[39m: test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransported\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted_transported\n\u001b[0;32m     26\u001b[0m })\n",
      "File \u001b[1;32mc:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:271\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:826\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    824\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32mc:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Cabin\n- Destination\n- HomePlanet\nFeature names seen at fit time, yet now missing:\n- Cabin_A/0/P\n- Cabin_A/0/S\n- Cabin_A/1/S\n- Cabin_A/10/P\n- Cabin_A/10/S\n- ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# 1. Baca data test set\n",
    "test_data = pd.read_csv('D:/BISMILLAHIRRAHMANIRRAHIM Informatics Engineering/SEMESTER 4/Mata Kuliah/Pengantar Pembelajaran Mesin/Project Battle/ppm-spaceship-titanic/test.csv')\n",
    "\n",
    "# 2. Lakukan pembersihan data test set (contoh: mengisi nilai kosong hanya untuk kolom numerik)\n",
    "numeric_columns = test_data.select_dtypes(include=['float64']).columns\n",
    "test_data_filled = test_data.copy()\n",
    "test_data_filled[numeric_columns] = test_data_filled[numeric_columns].fillna(test_data_filled[numeric_columns].mean())\n",
    "\n",
    "# 3. Pisahkan fitur dari target\n",
    "X_test = test_data_filled.drop(['PassengerId', 'Name'], axis=1)\n",
    "\n",
    "# 4. Muat model yang sudah dilatih sebelumnya\n",
    "with open('knn_model.pkl', 'rb') as f:\n",
    "    knn_model = pickle.load(f)\n",
    "\n",
    "# 5. Lakukan prediksi pada data test set\n",
    "predicted_transported = knn_model.predict(X_test)\n",
    "\n",
    "# 6. Simpan hasil prediksi ke dalam file CSV\n",
    "df_results = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Transported': predicted_transported\n",
    "})\n",
    "df_results.to_csv('path_to_save_test_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Cabin\n- Destination\n- HomePlanet\nFeature names seen at fit time, yet now missing:\n- Cabin_A/0/P\n- Cabin_A/0/S\n- Cabin_A/1/S\n- Cabin_A/10/P\n- Cabin_A/10/S\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     knn_model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Melakukan prediksi terhadap data uji menggunakan model yang telah dimuat\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m \u001b[43mknn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Baca kolom 'PassengerId' dari file sample_submission.csv\u001b[39;00m\n\u001b[0;32m     14\u001b[0m sample_submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/BISMILLAHIRRAHMANIRRAHIM Informatics Engineering/SEMESTER 4/Mata Kuliah/Pengantar Pembelajaran Mesin/Project Battle/ppm-spaceship-titanic/sample_submission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Ganti dengan path yang benar\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:271\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:826\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    824\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32mc:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\AHMAD ZAKI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Cabin\n- Destination\n- HomePlanet\nFeature names seen at fit time, yet now missing:\n- Cabin_A/0/P\n- Cabin_A/0/S\n- Cabin_A/1/S\n- Cabin_A/10/P\n- Cabin_A/10/S\n- ...\n"
     ]
    }
   ],
   "source": [
    "# Misalkan kita mengabaikan kolom 'PassengerPassengerId' dan 'Name' sebagai fitur karena tPassengerIdak relevan\n",
    "\n",
    "# Memisahkan fitur dari DataFrame test_data\n",
    "X_test = test_data.drop(['PassengerId', 'Name'], axis=1)\n",
    "\n",
    "# Memuat model yang sudah Anda latih sebelumnya\n",
    "with open('knn_model.pkl', 'rb') as f:\n",
    "    knn_model = pickle.load(f)\n",
    "\n",
    "# Melakukan prediksi terhadap data uji menggunakan model yang telah dimuat\n",
    "y_pred_test = knn_model.predict(X_test)\n",
    "\n",
    "# Baca kolom 'PassengerId' dari file sample_submission.csv\n",
    "sample_submission = pd.read_csv('D:/BISMILLAHIRRAHMANIRRAHIM Informatics Engineering/SEMESTER 4/Mata Kuliah/Pengantar Pembelajaran Mesin/Project Battle/ppm-spaceship-titanic/sample_submission.csv')  # Ganti dengan path yang benar\n",
    "\n",
    "# Pastikan indeks dimulai dari 0 hingga (jumlah baris - 1)\n",
    "sample_submission.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Buat DataFrame hasil prediksi\n",
    "df_results = pd.DataFrame({\n",
    "    'PassengerId': sample_submission['PassengerId'][:len(y_pred_test)],\n",
    "    'Transported': y_pred_test\n",
    "})\n",
    "\n",
    "# Gantilah 'path_to_save_test_results' dengan path tempat Anda ingin menyimpan file CSV\n",
    "path_to_save_test_results = \"test_results.csv\"\n",
    "# Simpan dataframe hasil prediksi ke dalam file CSV\n",
    "\n",
    "df_results.to_csv(path_to_save_test_results, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
